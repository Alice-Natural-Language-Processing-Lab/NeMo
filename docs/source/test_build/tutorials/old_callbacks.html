

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Callbacks V0.10 &mdash; nemo 0.11.0b9 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> nemo
          

          
          </a>

          
            
            
              <div class="version">
                0.11.0b9
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../training.html">Fast Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../asr/intro.html">Speech Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../speaker_recognition/intro.html">Speaker Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../speech_command/intro.html">Speech Commands</a></li>
<li class="toctree-l1"><a class="reference internal" href="../voice_activity_detection/intro.html">Voice Activity Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nlp/intro.html">Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tts/intro.html">Speech Synthesis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../collections/modules.html">NeMo Collections API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api-docs/modules.html">NeMo API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chinese/intro.html">中文支持</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">nemo</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Callbacks V0.10</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/tutorials/old_callbacks.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="callbacks-v0-10">
<span id="callbacks0-10"></span><h1>Callbacks V0.10<a class="headerlink" href="#callbacks-v0-10" title="Permalink to this headline">¶</a></h1>
<p>NeMo uses callbacks to do a variety of helper functions during training.
NeMo comes with three useful callbacks: SimpleLossLoggerCallback,
CheckpointCallback, and EvaluatorCallback. Callbacks are defined prior to
calling the train() function, and are passed to the train() function.
For example, a common training script will look like:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">loggercallback</span> <span class="o">=</span> <span class="n">nemo</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">SimpleLossLoggerCallback</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">savercallback</span> <span class="o">=</span> <span class="n">nemo</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">CheckpointCallback</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">evalcallback</span> <span class="o">=</span> <span class="n">nemo</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">EvaluatorCallback</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

<span class="n">nf</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">loggercallback</span><span class="p">,</span> <span class="n">savercallback</span><span class="p">,</span> <span class="n">evalcallback</span><span class="p">],</span>
    <span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="simplelossloggercallback">
<h2>SimpleLossLoggerCallback<a class="headerlink" href="#simplelossloggercallback" title="Permalink to this headline">¶</a></h2>
<p>SimpleLossLoggerCallback is used to
log training metrics such as loss and time per step to screen and to
tensorboard. SimpleLossLoggerCallback has one required arguments, and two
arguments that we recommend to overwrite. It requires tensors which is a list
of NMTensors that print_func(), get_tb_values(), and log_to_tb_func will
receive as input during
training. The two reccomended arguments to override are print_func(), and
either get_tb_values() or log_to_tb_func().</p>
<p>print_func() should be used to log values to screen. We recommend using
logging.info() in place
of print(). For example, it can be used to print the loss value:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nemo</span> <span class="kn">import</span> <span class="n">logging</span>
<span class="k">def</span> <span class="nf">my_print_func</span><span class="p">(</span><span class="n">tensors</span><span class="p">):</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;Loss {tensors[0]}&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>We provide two methods to log to tensorboard: get_tb_values() and
log_to_tb_func(). For simple use case of logging scalars, we recommend
get_tb_values(). For advanced use cases such as pictures or audio, we
recommend log_to_tb_func().</p>
<p>get_tb_values() is used to return values to be logged to tensorboard. It should
return a list of 2-element tuples, where the first element is a string
representing the tensorboard tag, and the second element is the scalar value to
log. Note we currently only support scalar values. Note to use get_tb_values(),
tb_writer should also be defined.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">my_get_tb_values</span><span class="p">(</span><span class="n">tensors</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[(</span><span class="s2">&quot;Train_Loss&quot;</span><span class="p">,</span> <span class="n">tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span>
</pre></div>
</div>
<p>log_to_tb_func() takes three arguments: the
<a class="reference external" href="https://tensorboardx.readthedocs.io/en/latest/tensorboard.html">tensorboardX.SummaryWriter</a>
, a list of evaluated tensors, and the current step. The user can then use the
SummaryWriter class to add images, audio, and more. For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">log_to_tb_func</span><span class="p">(</span><span class="n">swriter</span><span class="p">,</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
    <span class="n">swriter</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;Train_Loss&quot;</span><span class="p">,</span> <span class="n">tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">step</span><span class="p">)</span>
    <span class="n">swriter</span><span class="o">.</span><span class="n">add_audio</span><span class="p">(</span><span class="s2">&quot;Train_Sample&quot;</span><span class="p">,</span> <span class="n">tensors</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">step</span><span class="p">)</span>
</pre></div>
</div>
<p>SimpleLossLoggerCallback can be constructed as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">loggercallback</span> <span class="o">=</span> <span class="n">nemo</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">SimpleLossLoggerCallback</span><span class="p">(</span>
    <span class="c1"># Define tensors that we want to pass to print_func, and get_tb_values</span>
    <span class="n">tensors</span><span class="o">=</span><span class="p">[</span><span class="n">train_loss</span><span class="p">],</span>
    <span class="c1"># Pass the print function that we want to use</span>
    <span class="n">print_func</span><span class="o">=</span><span class="n">my_print_func</span><span class="p">,</span>
    <span class="c1"># Pass the function that returns tensorboard tags and scalars</span>
    <span class="n">get_tb_values</span><span class="o">=</span><span class="n">my_get_tb_values</span><span class="p">,</span>
    <span class="c1"># How often we want to call this callback</span>
    <span class="n">step_freq</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
    <span class="c1"># The tensorboard writer object we want to use, it should be</span>
    <span class="c1"># automatically created by neural_factory if create_tb_writer was</span>
    <span class="c1"># set to True during neural_factory construction</span>
    <span class="n">tb_writer</span><span class="o">=</span><span class="n">neural_factory</span><span class="o">.</span><span class="n">tb_writer</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="checkpointcallback">
<h2>CheckpointCallback<a class="headerlink" href="#checkpointcallback" title="Permalink to this headline">¶</a></h2>
<p>CheckpointCallback is used to checkpoint models during training so that
they can be reloaded later for inference or finetuning. CheckpointCallback
is simple to use:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">loggercallback</span> <span class="o">=</span> <span class="n">nemo</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">CheckpointCallback</span><span class="p">(</span>
    <span class="c1"># The folder to save checkpoints</span>
    <span class="c1"># Note: Neural Factory automatically creates a checkpoint folder</span>
    <span class="n">folder</span><span class="o">=</span><span class="n">neural_factory</span><span class="o">.</span><span class="n">checkpoint_dir</span><span class="p">,</span>
    <span class="c1"># If None, CheckpointCallback will attempt to load from folder</span>
    <span class="c1"># at the beginning of training.</span>
    <span class="c1"># Else, CheckpointCallback will attempt to load from load_from_folder</span>
    <span class="n">load_from_folder</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="c1"># Checkpointing frequency in steps</span>
    <span class="n">step_freq</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
    <span class="c1"># Checkpointing frequency in epochs</span>
    <span class="n">epoch_freq</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
    <span class="c1"># Number of checkpoints to keep</span>
    <span class="n">checkpoints_to_keep</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="c1"># If True, CheckpointCallback will raise an Error if restoring fails</span>
    <span class="n">force_load</span><span class="o">=</span><span class="bp">False</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="evaluatorcallback">
<h2>EvaluatorCallback<a class="headerlink" href="#evaluatorcallback" title="Permalink to this headline">¶</a></h2>
<p>EvaluatorCallback is used during evaluation to log evaluation
metrics to screen and tensorboard. EvaluatorCallback requires three arguments:
eval_tensors, user_iter_callback, user_epochs_done_callback. Similar to
SimpleLossLoggerCallback, eval_tensors is a list of NMTensors whose values
we want to obtain during evaluation.</p>
<p>user_iter_callback is a function that is called after each batch during
evaluation. It is always passed two arguments: values_dict, and global_var_dict.
values_dict is a dictionary containing NMTensor names as keys, and the evaluated
tensor as values for that batch. It’s main job is to copy the relevant evaluated
tensors from values_dict to global_var_dict as global_var_dict is saved
between batches and passed to the final user_epochs_done_callback function.</p>
<p>user_epochs_done_callback is a function that accepts global_var_dict. It’s job
is to log relevant information to the screen such as the evaluation loss.</p>
<p>For simple logging of scalar values to tensorboard, user_epochs_done_callback
should return a dictionary with strings as keys and scalar tensors as values.
This tag -&gt; value dictionary will be parsed and each element will be logged
to tensorboard if a tensorboard writter object is declared.</p>
<p>To enable more complex tensorboard logging such as images or audio,
EvaluatorCallback must be passed tb_writer_func at initialization. This
function must accept a
<a class="reference external" href="https://tensorboardx.readthedocs.io/en/latest/tensorboard.html">tensorboardX.SummaryWriter</a>
, whatever is returned from user_epochs_done_callback, and the current step.
We recommend for user_epochs_done_callback to simply return the global_var_dict
for tb_writer_func to consume. The user must log all data of interest inside
tb_writer_func including scalars that would otherwise be logged if
tb_writer_func was not passed to EvaluatorCallback.</p>
<p>You can also log your evaluation metrics into Weights &amp; Biases experiment trackers.
To do so, please setup these parameters. Also make sure wandb is installed and you did <code class="docutils literal notranslate"><span class="pre">wandb</span> <span class="pre">login</span></code>.</p>
<ul class="simple">
<li><p>wandb_name: W&amp;B experiment name</p></li>
<li><p>wandb_project: W&amp;B project name</p></li>
</ul>
<p>For an example, please see the scripts inside &lt;nemo_dir&gt;/examples.</p>
</div>
<div class="section" id="wandbcallback">
<h2>WandbCallback<a class="headerlink" href="#wandbcallback" title="Permalink to this headline">¶</a></h2>
<p>WandbCallback logs losses and metrics to <a class="reference external" href="https://docs.wandb.com/">Weights &amp; Biases</a>.
Make sure wandb is installed and you did <code class="docutils literal notranslate"><span class="pre">wandb</span> <span class="pre">login</span></code>.</p>
<p>This is a light-weight callback to log <strong>training</strong> metrics into Weights &amp; Biases.
To log evaluation metrics, see Evaluator Callback above.</p>
<p>It requires following arguments:</p>
<ul class="simple">
<li><p>train_tensors: list of tensors to evaluate and log based on training batches</p></li>
<li><p>wandb_name: W&amp;B experiment name</p></li>
<li><p>wandb_project: W&amp;B project name</p></li>
<li><p>args: argparse flags - will be logged as hyper parameters for your run</p></li>
<li><p>update_freq: frequency with which to log updates</p></li>
</ul>
</div>
</div>
<div class="section" id="updating-to-callbacks-to-nemo-v0-11">
<span id="callbacks0-10update"></span><h1>Updating to Callbacks to NeMo V0.11<a class="headerlink" href="#updating-to-callbacks-to-nemo-v0-11" title="Permalink to this headline">¶</a></h1>
<p>As of v0.11, only training callbacks after been updated, thus <code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.core.callbacks.EvaluatorCallback</span></code> still
remains the correct method of adding evaluation logic to the training loop.
<a class="reference internal" href="../api-docs/nemo.html#nemo.core.callbacks.CheckpointCallback" title="nemo.core.callbacks.CheckpointCallback"><code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.core.callbacks.CheckpointCallback</span></code></a> has been updated to the new callback system and is fully backwards
compatible.</p>
<p><code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.core.callbacks.WandbCallback</span></code> is succeeded by <a class="reference internal" href="../api-docs/nemo.html#nemo.core.callbacks.WandBLogger" title="nemo.core.callbacks.WandBLogger"><code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.core.callbacks.WandBLogger</span></code></a>. There are a few
changes to the instantiation of the callback. <code class="docutils literal notranslate"><span class="pre">update_freq</span></code> has been changed to <code class="docutils literal notranslate"><span class="pre">step_freq</span></code>. <code class="docutils literal notranslate"><span class="pre">train_tensors</span></code> has
been changed to <code class="docutils literal notranslate"><span class="pre">tensors_to_log</span></code>. The new callback <a class="reference internal" href="../api-docs/nemo.html#nemo.core.callbacks.WandBLogger" title="nemo.core.callbacks.WandBLogger"><code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.core.callbacks.WandBLogger</span></code></a> contains 2 additional
boolean parameters which default to True: <code class="docutils literal notranslate"><span class="pre">log_epoch</span></code> which controls the logging of epoch statistics, and <code class="docutils literal notranslate"><span class="pre">log_lr</span></code>
which controls the logging of the learning rate.</p>
<p><code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.core.callbacks.SimpleLossLoggerCallback</span></code> has been split into <a class="reference internal" href="../api-docs/nemo.html#nemo.core.callbacks.SimpleLogger" title="nemo.core.callbacks.SimpleLogger"><code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.core.callbacks.SimpleLogger</span></code></a>
and <a class="reference internal" href="../api-docs/nemo.html#nemo.core.callbacks.TensorboardLogger" title="nemo.core.callbacks.TensorboardLogger"><code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.core.callbacks.TensorboardLogger</span></code></a> which controls screen output and tensorboard output respectively.
In terms of argument changes, <code class="docutils literal notranslate"><span class="pre">tensors</span></code> has been changed to <code class="docutils literal notranslate"><span class="pre">tensors_to_log</span></code>. <code class="docutils literal notranslate"><span class="pre">print_func</span></code> has been removed from
<a class="reference internal" href="../api-docs/nemo.html#nemo.core.callbacks.SimpleLogger" title="nemo.core.callbacks.SimpleLogger"><code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.core.callbacks.SimpleLogger</span></code></a>. The new <cite>SimpleLogger</cite> simply prints the entire tensor. If a more complex
printing methods such as printing 1 element or 1 dimension, please look into <a class="reference internal" href="callbacks.html#callback-creation"><span class="std std-ref">Creating Your Own Callback</span></a>. For
<a class="reference internal" href="../api-docs/nemo.html#nemo.core.callbacks.TensorboardLogger" title="nemo.core.callbacks.TensorboardLogger"><code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.core.callbacks.TensorboardLogger</span></code></a>, <code class="docutils literal notranslate"><span class="pre">get_tb_values</span></code>, and <code class="docutils literal notranslate"><span class="pre">log_to_tb_func</span></code> have been removed. By
default <cite>TensorboardLogger</cite> assumes each tensors passed to it in <code class="docutils literal notranslate"><span class="pre">tensors_to_log</span></code> is a scalar and logs it to
tensorboard as a scalar. For more advanced functionality, <cite>TensorboardLogger</cite> accepts <code class="docutils literal notranslate"><span class="pre">custom_tb_log_func</span></code> which
obtains the values of all tensors from <code class="docutils literal notranslate"><span class="pre">tensors_to_log</span></code>. In peusdocode, its looks like:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tensor_values</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">tensors_to_log</span><span class="p">:</span>
    <span class="n">tensor_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;tensors&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="n">tensor</span><span class="p">))</span>  <span class="c1"># Appends a pytorch tensor to tensor_values</span>
<span class="n">custom_tb_log_func</span><span class="p">(</span>
    <span class="n">tensor_values</span><span class="p">,</span>  <span class="c1"># The list of pytorch tensors associated with tensors_to_log</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tb_writer</span><span class="p">,</span>  <span class="c1"># The tensorboard SummaryWriter class</span>
    <span class="n">state</span><span class="p">[</span><span class="s2">&quot;step&quot;</span><span class="p">],</span>  <span class="c1"># The current training step</span>
<span class="p">)</span>
</pre></div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018-2020, NVIDIA

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>