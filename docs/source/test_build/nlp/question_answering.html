

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Tutorial &mdash; nemo 0.11.0b9 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="TRADE Tutorial" href="dialogue_state_tracking_trade.html" />
    <link rel="prev" title="Tutorial" href="punctuation.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> nemo
          

          
          </a>

          
            
            
              <div class="version">
                0.11.0b9
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/intro.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../training.html">Fast Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../asr/intro.html">Speech Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../speaker_recognition/intro.html">Speaker Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../speech_command/intro.html">Speech Commands</a></li>
<li class="toctree-l1"><a class="reference internal" href="../voice_activity_detection/intro.html">Voice Activity Detection</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="intro.html">Natural Language Processing</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="intro.html#neural-machine-translation-nmt">Neural Machine Translation (NMT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#pretraining-bert">Pretraining BERT</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#transformer-language-model">Transformer Language Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#megatron-lm-for-downstream-tasks">Megatron-LM for Downstream tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#glue-benchmark">GLUE Benchmark</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#intent-and-slot-filling">Intent and Slot filling</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#text-classification">Text Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#named-entity-recognition">Named Entity Recognition</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#punctuation-and-word-capitalization">Punctuation and Word Capitalization</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="intro.html#question-answering">Question Answering</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Tutorial</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#download-pretrained-models">Download pretrained models</a></li>
<li class="toctree-l4"><a class="reference internal" href="#preliminaries">Preliminaries</a></li>
<li class="toctree-l4"><a class="reference internal" href="#code-structure">Code structure</a></li>
<li class="toctree-l4"><a class="reference internal" href="#model-training">Model training</a></li>
<li class="toctree-l4"><a class="reference internal" href="#bioqa">BioQA</a></li>
<li class="toctree-l4"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#dialogue-state-tracking">Dialogue State Tracking</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#asr-postprocessing-with-bert">ASR Postprocessing with BERT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../tts/intro.html">Speech Synthesis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../collections/modules.html">NeMo Collections API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api-docs/modules.html">NeMo API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../chinese/intro.html">中文支持</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">nemo</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="intro.html">Natural Language Processing</a> &raquo;</li>
        
      <li>Tutorial</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/nlp/question_answering.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="tutorial">
<span id="squad-model-links"></span><h1>Tutorial<a class="headerlink" href="#tutorial" title="Permalink to this headline">¶</a></h1>
<p>In this tutorial, we are going to implement a Question Answering system using the SQuAD dataset with pretrained BERT-like models based on
<a class="reference external" href="https://arxiv.org/abs/1810.04805">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a> <a class="bibtex reference internal" href="#nlp-qa-devlin2018bert" id="id1">[NLP-QA1]</a>.
All code used in this tutorial is based on <code class="docutils literal notranslate"><span class="pre">examples/nlp/question_answering/question_answering_squad.py</span></code>.</p>
<p>Currently, there are 4 pretrained back-bone models supported, on which the question answering task SQuAD can be fine-tuned:
Megatron-LM BERT, BERT, ALBERT and RoBERTa. These are pretrained model checkpoints from <a class="reference external" href="https://huggingface.co/transformers">transformers</a> . Apart from these, the user can also do fine-tuning
on a custom BERT checkpoint, specified by the <cite>–bert_checkpoint</cite> argument.
The pretrained back-bone models can be specified <cite>–pretrained_model_name</cite>.
See the list of available pre-trained models
<a class="reference external" href="https://huggingface.co/transformers/pretrained_models.html">here</a>.</p>
<div class="section" id="download-pretrained-models">
<span id="pretrained-models-squad"></span><h2>Download pretrained models<a class="headerlink" href="#download-pretrained-models" title="Permalink to this headline">¶</a></h2>
<p>Finetuned SQuAD models and model configuration files can be downloaded at following links.</p>
<p>BERT Base uncased models (~330M parameters) finetuned on SQuADv1.1 or SQuADv2.0 dataset:
<a class="reference external" href="https://ngc.nvidia.com/catalog/models/nvidia:bertbaseuncasedsquadv1">https://ngc.nvidia.com/catalog/models/nvidia:bertbaseuncasedsquadv1</a>
<a class="reference external" href="https://ngc.nvidia.com/catalog/models/nvidia:bertbaseuncasedsquadv2">https://ngc.nvidia.com/catalog/models/nvidia:bertbaseuncasedsquadv2</a></p>
<p>BERT Large uncased models (~110M parameters) finetuned on SQuADv1.1 or SQuADv2.0 dataset:
<a class="reference external" href="https://ngc.nvidia.com/catalog/models/nvidia:bertlargeuncasedsquadv1">https://ngc.nvidia.com/catalog/models/nvidia:bertlargeuncasedsquadv1</a>
<a class="reference external" href="https://ngc.nvidia.com/catalog/models/nvidia:bertlargeuncasedsquadv2">https://ngc.nvidia.com/catalog/models/nvidia:bertlargeuncasedsquadv2</a></p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>For pretraining BERT in NeMo and pretrained model checkpoints go to <a class="reference external" href="https://nvidia.github.io/NeMo/nlp/bert_pretraining.html">BERT pretraining</a>.</p>
</div>
<p>Model results:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 58%" />
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 10%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head" rowspan="2"><p>Model</p></th>
<th class="head" colspan="2"><p>SQuADv1.1</p></th>
<th class="head" colspan="2"><p>SQuADv2.0</p></th>
</tr>
<tr class="row-even"><th class="head"><p>EM</p></th>
<th class="head"><p>F1</p></th>
<th class="head"><p>EM</p></th>
<th class="head"><p>F1</p></th>
</tr>
</thead>
<tbody>
<tr class="row-odd"><td><p>BERT-base-uncased</p></td>
<td><p>82.74%</p></td>
<td><p>89.79%</p></td>
<td><p>71.24%</p></td>
<td><p>74.32%</p></td>
</tr>
<tr class="row-even"><td><p>BERT-large-uncased</p></td>
<td><p>85.79%</p></td>
<td><p>92.28%</p></td>
<td><p>80.17%</p></td>
<td><p>83.32%</p></td>
</tr>
</tbody>
</table>
<p>On a DGX1 with 8 V100 16GB training on SQuADv1.1 with the default script parameters takes between 14-18 minutes.</p>
</div>
<div class="section" id="preliminaries">
<h2>Preliminaries<a class="headerlink" href="#preliminaries" title="Permalink to this headline">¶</a></h2>
<p><strong>Model details</strong>
This model trains token-level classifier to predict the start and end position of the answer span in context.
The loss is composed of the sum of the cross entropy loss of the start <cite>S_loss</cite> and end positions <cite>E_loss</cite>:</p>
<blockquote>
<div><p><cite>S_loss</cite> + <cite>E_loss</cite></p>
</div></blockquote>
<p>At inference, the longest answer span that minimizes this loss is used as prediction.</p>
<p><strong>Datasets.</strong></p>
<p>This model can work with any dataset that follows the format:</p>
<blockquote>
<div><ul class="simple">
<li><p>training file: a <cite>json</cite> file of this structure</p></li>
</ul>
<p>{“data”:[{“title”: “string”, “paragraphs”: [{“context”: “string”, “qas”: [{“question”: “string”, “is_impossible”: “bool”, “id”: “number”, “answers”: [{“answer_start”: “number”, “text”: “string”, }]}]}]}]}
“answers” can also be empty if the model should also learn questions with impossible answers. In this case pass <cite>–version_2_with_negative</cite></p>
<ul class="simple">
<li><p>evaluation file: a <cite>json</cite> file that follows the training file format
only that it can provide more than one entry for “answers” to the same question</p></li>
<li><p>test file: a <cite>json</cite> file that follows the training file format
only that it does not require the “answers” keyword.</p></li>
</ul>
</div></blockquote>
<p>Currently, the datasets that we provide pre-processing script for is SQuAD v1.1 and v2.0
which can be downloaded
from <a class="reference external" href="https://rajpurkar.github.io/SQuAD-explorer/">https://rajpurkar.github.io/SQuAD-explorer/</a>.
You can find the pre-processing script in <code class="docutils literal notranslate"><span class="pre">examples/nlp/question_answering/get_squad.py</span></code>.</p>
</div>
<div class="section" id="code-structure">
<h2>Code structure<a class="headerlink" href="#code-structure" title="Permalink to this headline">¶</a></h2>
<p>First, we instantiate Neural Module Factory which defines 1) backend (PyTorch), 2) mixed precision optimization level,
3) local rank of the GPU, and 4) an experiment manager that creates a timestamped folder to store checkpoints, relevant outputs, log files, and TensorBoard graphs.</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nemo</span>
<span class="kn">import</span> <span class="nn">nemo.collections.nlp</span> <span class="kn">as</span> <span class="nn">nemo_nlp</span>
<span class="n">nf</span> <span class="o">=</span> <span class="n">nemo</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">NeuralModuleFactory</span><span class="p">(</span><span class="n">local_rank</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">local_rank</span><span class="p">,</span>
                                       <span class="n">optimization_level</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">amp_opt_level</span><span class="p">,</span>
                                       <span class="n">log_dir</span><span class="o">=</span><span class="n">work_dir</span><span class="p">,</span>
                                       <span class="n">create_tb_writer</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                                       <span class="n">files_to_copy</span><span class="o">=</span><span class="p">[</span><span class="vm">__file__</span><span class="p">],</span>
                                       <span class="n">add_time_to_log_dir</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p>Next, we define all Neural Modules participating in our question answering classification pipeline.</p>
<blockquote>
<div><ul class="simple">
<li><p>Process data: the <cite>BertQuestionAnsweringDataLayer</cite> is supposed to do the preprocessing of raw data into the format data supported by <cite>SquadDataset</cite>.</p></li>
</ul>
<p>Training and evaluation each require their own <cite>BertQuestionAnsweringDataLayer</cite>.
DataLayer is an extra layer to do the semantic checking for your dataset and convert it into DataLayerNM.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data_layer</span> <span class="o">=</span> <span class="n">nemo_nlp</span><span class="o">.</span><span class="n">nm</span><span class="o">.</span><span class="n">data_layers</span><span class="o">.</span><span class="n">BertQuestionAnsweringDataLayer</span><span class="p">(</span>
                        <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">,</span>
                        <span class="n">data_file</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train_file</span><span class="p">,</span>
                        <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
                        <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                        <span class="n">version_2_with_negative</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">version_2_with_negative</span><span class="p">,</span>
                        <span class="n">max_query_length</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">max_query_length</span><span class="p">,</span>
                        <span class="n">max_seq_length</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span>
                        <span class="n">doc_stride</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">doc_stride</span><span class="p">,</span>
                        <span class="n">use_cache</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">use_data_cache</span><span class="p">)</span>


<span class="n">data_layer_eval</span> <span class="o">=</span> <span class="n">nemo_nlp</span><span class="o">.</span><span class="n">nm</span><span class="o">.</span><span class="n">data_layers</span><span class="o">.</span><span class="n">BertQuestionAnsweringDataLayer</span><span class="p">(</span>
                        <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;eval&#39;</span><span class="p">,</span>
                        <span class="n">data_file</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">eval_file</span><span class="p">,</span>
                        <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
                        <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                        <span class="n">version_2_with_negative</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">version_2_with_negative</span><span class="p">,</span>
                        <span class="n">max_query_length</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">max_query_length</span><span class="p">,</span>
                        <span class="n">max_seq_length</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span>
                        <span class="n">doc_stride</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">doc_stride</span><span class="p">,</span>
                        <span class="n">use_cache</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">use_data_cache</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Load the pretrained model and get the hidden states for the corresponding inputs.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">args</span><span class="o">.</span><span class="n">pretrained_model_name</span> <span class="o">=</span> <span class="s2">&quot;bert-base-uncased&quot;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">nemo_nlp</span><span class="o">.</span><span class="n">nm</span><span class="o">.</span><span class="n">trainables</span><span class="o">.</span><span class="n">huggingface</span><span class="o">.</span><span class="n">BERT</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">pretrained_model_name</span><span class="p">)</span>
<span class="c1"># or for RoBERTa</span>
<span class="n">args</span><span class="o">.</span><span class="n">pretrained_model_name</span> <span class="o">=</span> <span class="s2">&quot;roberta-base&quot;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">nemo_nlp</span><span class="o">.</span><span class="n">nm</span><span class="o">.</span><span class="n">trainables</span><span class="o">.</span><span class="n">huggingface</span><span class="o">.</span><span class="n">Roberta</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">pretrained_model_name</span><span class="p">)</span>
<span class="c1"># or for Albert</span>
<span class="n">args</span><span class="o">.</span><span class="n">pretrained_model_name</span> <span class="o">=</span> <span class="s2">&quot;albert-base-v1&quot;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">nemo_nlp</span><span class="o">.</span><span class="n">nm</span><span class="o">.</span><span class="n">trainables</span><span class="o">.</span><span class="n">huggingface</span><span class="o">.</span><span class="n">Albert</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">pretrained_model_name</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Define the tokenizer which transforms text into BERT tokens, using <cite>NemoBertTokenizer</cite>. This will tokenize text following the mapping of the original BERT model.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">hidden_size</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nemo_nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">NemoBertTokenizer</span><span class="p">(</span><span class="n">pretrained_model</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">pretrained_model_name</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create the classifier head for our task.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">qa_head</span> <span class="o">=</span> <span class="n">nemo_nlp</span><span class="o">.</span><span class="n">nm</span><span class="o">.</span><span class="n">trainables</span><span class="o">.</span><span class="n">TokenClassifier</span><span class="p">(</span>
                        <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span>
                        <span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                        <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">log_softmax</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create loss function</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nemo_nlp</span><span class="o">.</span><span class="n">nm</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SpanningLoss</span><span class="p">()</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create the pipelines for the train and evaluation processes.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># training graph</span>
<span class="n">input_data</span> <span class="o">=</span> <span class="n">data_layer</span><span class="p">()</span>
<span class="n">hidden_states</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_data</span><span class="o">.</span><span class="n">input_ids</span><span class="p">,</span>
                <span class="n">token_type_ids</span><span class="o">=</span><span class="n">input_data</span><span class="o">.</span><span class="n">input_type_ids</span><span class="p">,</span>
                <span class="n">attention_mask</span><span class="o">=</span><span class="n">input_data</span><span class="o">.</span><span class="n">input_mask</span><span class="p">)</span>

<span class="n">qa_logits</span> <span class="o">=</span> <span class="n">qa_head</span><span class="p">(</span><span class="n">hidden_states</span><span class="o">=</span><span class="n">hidden_states</span><span class="p">)</span>
<span class="n">loss_outputs</span> <span class="o">=</span> <span class="n">squad_loss</span><span class="p">(</span>
    <span class="n">logits</span><span class="o">=</span><span class="n">qa_logits</span><span class="p">,</span>
    <span class="n">start_positions</span><span class="o">=</span><span class="n">input_data</span><span class="o">.</span><span class="n">start_positions</span><span class="p">,</span>
    <span class="n">end_positions</span><span class="o">=</span><span class="n">input_data</span><span class="o">.</span><span class="n">end_positions</span><span class="p">)</span>
<span class="n">train_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">loss_outputs</span><span class="o">.</span><span class="n">loss</span><span class="p">]</span>

<span class="c1"># evaluation graph</span>
<span class="n">input_data_eval</span> <span class="o">=</span> <span class="n">data_layer_eval</span><span class="p">()</span>

<span class="n">hidden_states_eval</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span>
    <span class="n">input_ids</span><span class="o">=</span><span class="n">input_data_eval</span><span class="o">.</span><span class="n">input_ids</span><span class="p">,</span>
    <span class="n">token_type_ids</span><span class="o">=</span><span class="n">input_data_eval</span><span class="o">.</span><span class="n">input_type_ids</span><span class="p">,</span>
    <span class="n">attention_mask</span><span class="o">=</span><span class="n">input_data_eval</span><span class="o">.</span><span class="n">input_mask</span><span class="p">)</span>

<span class="n">qa_logits_eval</span> <span class="o">=</span> <span class="n">qa_head</span><span class="p">(</span><span class="n">hidden_states</span><span class="o">=</span><span class="n">hidden_states_eval</span><span class="p">)</span>
<span class="n">loss_outputs_eval</span> <span class="o">=</span> <span class="n">squad_loss</span><span class="p">(</span>
    <span class="n">logits</span><span class="o">=</span><span class="n">qa_logits_eval</span><span class="p">,</span>
    <span class="n">start_positions</span><span class="o">=</span><span class="n">input_data_eval</span><span class="o">.</span><span class="n">start_positions</span><span class="p">,</span>
    <span class="n">end_positions</span><span class="o">=</span><span class="n">input_data_eval</span><span class="o">.</span><span class="n">end_positions</span><span class="p">)</span>
<span class="n">eval_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">input_data_eval</span><span class="o">.</span><span class="n">unique_ids</span><span class="p">,</span> <span class="n">loss_outputs_eval</span><span class="o">.</span><span class="n">start_logits</span><span class="p">,</span> <span class="n">loss_outputs_eval</span><span class="o">.</span><span class="n">end_logits</span><span class="p">]</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Create relevant callbacks for saving checkpoints, printing training progresses and evaluating results.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">train_callback</span> <span class="o">=</span> <span class="n">nemo</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">SimpleLossLoggerCallback</span><span class="p">(</span>
    <span class="n">tensors</span><span class="o">=</span><span class="n">train_tensors</span><span class="p">,</span>
    <span class="n">print_func</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loss: {:.3f}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())),</span>
    <span class="n">get_tb_values</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">[[</span><span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]]],</span>
    <span class="n">step_freq</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">step_freq</span><span class="p">,</span>
    <span class="n">tb_writer</span><span class="o">=</span><span class="n">neural_factory</span><span class="o">.</span><span class="n">tb_writer</span><span class="p">)</span>


<span class="n">eval_callback</span> <span class="o">=</span> <span class="n">nemo</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">EvaluatorCallback</span><span class="p">(</span>
    <span class="n">eval_tensors</span><span class="o">=</span><span class="n">eval_tensors</span><span class="p">,</span>
    <span class="n">user_iter_callback</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">eval_iter_callback</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span>
    <span class="n">user_epochs_done_callback</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span>
        <span class="n">eval_epochs_done_callback</span><span class="p">(</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">eval_data_layer</span><span class="o">=</span><span class="n">data_layer_eval</span><span class="p">,</span>
            <span class="n">do_lower_case</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">do_lower_case</span><span class="p">,</span>
            <span class="n">n_best_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">n_best_size</span><span class="p">,</span>
            <span class="n">max_answer_length</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">max_answer_length</span><span class="p">,</span>
            <span class="n">version_2_with_negative</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">version_2_with_negative</span><span class="p">,</span>
            <span class="n">null_score_diff_threshold</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">null_score_diff_threshold</span><span class="p">),</span>
        <span class="n">tb_writer</span><span class="o">=</span><span class="n">neural_factory</span><span class="o">.</span><span class="n">tb_writer</span><span class="p">,</span>
        <span class="n">eval_step</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">eval_step_freq</span><span class="p">)</span>

<span class="n">ckpt_callback</span> <span class="o">=</span> <span class="n">nemo</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">CheckpointCallback</span><span class="p">(</span>
    <span class="n">folder</span><span class="o">=</span><span class="n">nf</span><span class="o">.</span><span class="n">checkpoint_dir</span><span class="p">,</span>
    <span class="n">epoch_freq</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">save_epoch_freq</span><span class="p">,</span>
    <span class="n">step_freq</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">save_step_freq</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Finally, we define the optimization parameters and run the whole pipeline.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">lr_policy_fn</span> <span class="o">=</span> <span class="n">get_lr_policy</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">lr_policy</span><span class="p">,</span>
                             <span class="n">total_steps</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_epochs</span> <span class="o">*</span> <span class="n">steps_per_epoch</span><span class="p">,</span>
                             <span class="n">warmup_ratio</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">lr_warmup_proportion</span><span class="p">)</span>

<span class="n">nf</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">tensors_to_optimize</span><span class="o">=</span><span class="n">train_tensors</span><span class="p">,</span>
         <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">train_callback</span><span class="p">,</span> <span class="n">eval_callback</span><span class="p">,</span> <span class="n">ckpt_callback</span><span class="p">],</span>
         <span class="n">lr_policy</span><span class="o">=</span><span class="n">lr_policy_fn</span><span class="p">,</span>
         <span class="n">optimizer</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">optimizer_kind</span><span class="p">,</span>
         <span class="n">optimization_params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;num_epochs&quot;</span><span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">num_epochs</span><span class="p">,</span>
                              <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span>
                              <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">})</span>
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="model-training">
<h2>Model training<a class="headerlink" href="#model-training" title="Permalink to this headline">¶</a></h2>
<p>To run on a single GPU, run:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">question_answering_squad</span><span class="o">.</span><span class="n">py</span> \
    <span class="o">...</span>
</pre></div>
</div>
</div></blockquote>
<p>To train a question answering model on SQuAD using multi-gpu, run <code class="docutils literal notranslate"><span class="pre">question_answering_squad.py</span></code> located at <code class="docutils literal notranslate"><span class="pre">examples/nlp/question_answering</span></code>:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">launch</span> <span class="o">--</span><span class="n">nproc_per_node</span><span class="o">=</span><span class="mi">8</span> <span class="n">question_answering_squad</span><span class="o">.</span><span class="n">py</span>
    <span class="o">--</span><span class="n">train_file</span> <span class="o">&lt;</span><span class="n">path</span> <span class="n">to</span> <span class="n">train</span> <span class="nb">file</span> <span class="ow">in</span> <span class="o">*.</span><span class="n">json</span> <span class="n">format</span><span class="o">&gt;</span>
    <span class="o">--</span><span class="n">eval_file</span> <span class="o">&lt;</span><span class="n">path</span> <span class="n">to</span> <span class="n">evaluation</span> <span class="nb">file</span> <span class="ow">in</span> <span class="o">*.</span><span class="n">json</span> <span class="n">format</span><span class="o">&gt;</span>
    <span class="o">--</span><span class="n">num_gpus</span> <span class="mi">8</span>
    <span class="o">--</span><span class="n">work_dir</span> <span class="o">&lt;</span><span class="n">where</span> <span class="n">you</span> <span class="n">want</span> <span class="n">to</span> <span class="n">log</span> <span class="n">your</span> <span class="n">experiment</span><span class="o">&gt;</span>
    <span class="o">--</span><span class="n">amp_opt_level</span> <span class="o">&lt;</span><span class="n">amp</span> <span class="n">optimization</span> <span class="n">level</span><span class="o">&gt;</span>
    <span class="o">--</span><span class="n">pretrained_model_name</span> <span class="o">&lt;</span><span class="nb">type</span> <span class="n">of</span> <span class="n">model</span> <span class="n">to</span> <span class="n">use</span><span class="o">&gt;</span>
    <span class="o">--</span><span class="n">bert_checkpoint</span> <span class="o">&lt;</span><span class="n">pretrained</span> <span class="n">bert</span> <span class="n">checkpoint</span><span class="o">&gt;</span>
    <span class="o">--</span><span class="n">bert_config</span> <span class="o">&lt;</span><span class="n">model</span> <span class="n">configuration</span> <span class="nb">file</span><span class="o">&gt;</span>
    <span class="o">--</span><span class="n">mode</span> <span class="s2">&quot;train_eval&quot;</span>
    <span class="o">...</span>
</pre></div>
</div>
</div></blockquote>
<p>For model configuration files and checkpoints, see <a class="reference internal" href="#pretrained-models-squad"><span class="std std-ref">Download pretrained models</span></a>.</p>
<p>To run evaluation:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">question_answering_squad</span><span class="o">.</span><span class="n">py</span>
    <span class="o">--</span><span class="n">eval_file</span> <span class="o">&lt;</span><span class="n">path</span> <span class="n">to</span> <span class="n">evaluation</span> <span class="nb">file</span> <span class="ow">in</span> <span class="o">*.</span><span class="n">json</span> <span class="n">format</span><span class="o">&gt;</span>
    <span class="o">--</span><span class="n">checkpoint_dir</span> <span class="o">&lt;</span><span class="n">path</span> <span class="n">to</span> <span class="n">trained</span> <span class="n">SQuAD</span> <span class="n">checkpoint</span> <span class="n">folder</span><span class="o">&gt;</span>
    <span class="o">--</span><span class="n">mode</span> <span class="s2">&quot;eval&quot;</span>
    <span class="o">--</span><span class="n">output_prediction_file</span> <span class="o">&lt;</span><span class="n">path</span> <span class="n">to</span> <span class="n">output</span> <span class="nb">file</span> <span class="n">where</span> <span class="n">predictions</span> <span class="n">are</span> <span class="n">written</span> <span class="n">into</span><span class="o">&gt;</span>
    <span class="o">...</span>
</pre></div>
</div>
</div></blockquote>
<p>To run inference:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">question_answering_squad</span><span class="o">.</span><span class="n">py</span>
    <span class="o">--</span><span class="n">test_file</span> <span class="o">&lt;</span><span class="n">path</span> <span class="n">to</span> <span class="n">evaluation</span> <span class="nb">file</span> <span class="ow">in</span> <span class="o">*.</span><span class="n">json</span> <span class="n">format</span><span class="o">&gt;</span>
    <span class="o">--</span><span class="n">checkpoint_dir</span> <span class="o">&lt;</span><span class="n">path</span> <span class="n">to</span> <span class="n">trained</span> <span class="n">SQuAD</span> <span class="n">checkpoint</span> <span class="n">folder</span><span class="o">&gt;</span>
    <span class="o">--</span><span class="n">mode</span> <span class="s2">&quot;test&quot;</span>
    <span class="o">--</span><span class="n">output_prediction_file</span> <span class="o">&lt;</span><span class="n">path</span> <span class="n">to</span> <span class="n">output</span> <span class="nb">file</span> <span class="n">where</span> <span class="n">predictions</span> <span class="n">are</span> <span class="n">written</span> <span class="n">into</span><span class="o">&gt;</span>
    <span class="o">...</span>
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="bioqa">
<h2>BioQA<a class="headerlink" href="#bioqa" title="Permalink to this headline">¶</a></h2>
<p>To use BioBERT/BioMegatron for biomedical question answering dataset BioASQ please visit:</p>
<p><a class="reference external" href="https://github.com/NVIDIA/NeMo/blob/master/examples/nlp/biobert_notebooks/biobert_qa.ipynb">https://github.com/NVIDIA/NeMo/blob/master/examples/nlp/biobert_notebooks/biobert_qa.ipynb</a></p>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p id="bibtex-bibliography-nlp/question_answering-0"><dl class="citation">
<dt class="bibtex label" id="nlp-qa-devlin2018bert"><span class="brackets"><a class="fn-backref" href="#id1">NLP-QA1</a></span></dt>
<dd><p>Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: pre-training of deep bidirectional transformers for language understanding. <em>arXiv preprint arXiv:1810.04805</em>, 2018.</p>
</dd>
</dl>
</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="dialogue_state_tracking_trade.html" class="btn btn-neutral float-right" title="TRADE Tutorial" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="punctuation.html" class="btn btn-neutral float-left" title="Tutorial" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018-2020, NVIDIA

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>