

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>nemo.core.neural_modules &mdash; nemo 0.11.0b9 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home"> nemo
          

          
          </a>

          
            
            
              <div class="version">
                0.11.0b9
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../index.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/intro.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../training.html">Fast Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../asr/intro.html">Speech Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../speaker_recognition/intro.html">Speaker Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../speech_command/intro.html">Speech Commands</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../voice_activity_detection/intro.html">Voice Activity Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../nlp/intro.html">Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tts/intro.html">Speech Synthesis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../collections/modules.html">NeMo Collections API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api-docs/modules.html">NeMo API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../chinese/intro.html">中文支持</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">nemo</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>nemo.core.neural_modules</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for nemo.core.neural_modules</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) 2019-, NVIDIA CORPORATION. All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;WeightShareTransform&#39;</span><span class="p">,</span> <span class="s1">&#39;NeuralModule&#39;</span><span class="p">,</span> <span class="s1">&#39;PretrainedModelInfo&#39;</span><span class="p">,</span> <span class="s1">&#39;ModuleType&#39;</span><span class="p">,</span> <span class="s1">&#39;OperationMode&#39;</span><span class="p">]</span>

<span class="kn">import</span> <span class="nn">uuid</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="k">import</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">namedtuple</span>
<span class="kn">from</span> <span class="nn">enum</span> <span class="k">import</span> <span class="n">Enum</span>
<span class="kn">from</span> <span class="nn">inspect</span> <span class="k">import</span> <span class="n">getargvalues</span><span class="p">,</span> <span class="n">getfullargspec</span><span class="p">,</span> <span class="n">stack</span>
<span class="kn">from</span> <span class="nn">os</span> <span class="k">import</span> <span class="n">path</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="k">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Set</span><span class="p">,</span> <span class="n">Tuple</span>

<span class="kn">from</span> <span class="nn">ruamel.yaml</span> <span class="k">import</span> <span class="n">YAML</span>

<span class="kn">from</span> <span class="nn">nemo.core.neural_factory</span> <span class="k">import</span> <span class="n">NeuralModuleFactory</span><span class="p">,</span> <span class="n">OperationMode</span>
<span class="kn">from</span> <span class="nn">nemo.core.neural_interface</span> <span class="k">import</span> <span class="n">NeuralInterface</span>
<span class="kn">from</span> <span class="nn">nemo.core.neural_types</span> <span class="k">import</span> <span class="n">NeuralPortNameMismatchError</span><span class="p">,</span> <span class="n">NeuralType</span><span class="p">,</span> <span class="n">NmTensor</span>
<span class="kn">from</span> <span class="nn">nemo.package_info</span> <span class="k">import</span> <span class="n">__version__</span> <span class="k">as</span> <span class="n">nemo_version</span>
<span class="kn">from</span> <span class="nn">nemo.utils</span> <span class="k">import</span> <span class="n">logging</span>
<span class="kn">from</span> <span class="nn">nemo.utils.decorators.deprecated</span> <span class="k">import</span> <span class="n">deprecated</span>
<span class="kn">from</span> <span class="nn">nemo.utils.neural_graph.connection</span> <span class="k">import</span> <span class="n">StepModulePort</span>

<span class="n">YAML</span> <span class="o">=</span> <span class="n">YAML</span><span class="p">(</span><span class="n">typ</span><span class="o">=</span><span class="s1">&#39;safe&#39;</span><span class="p">)</span>


<div class="viewcode-block" id="ModuleType"><a class="viewcode-back" href="../../../api-docs/nemo.html#nemo.core.neural_modules.ModuleType">[docs]</a><span class="k">class</span> <span class="nc">ModuleType</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Back-end independent module types &quot;&quot;&quot;</span>

    <span class="n">module</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">datalayer</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">trainable</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">nontrainable</span> <span class="o">=</span> <span class="mi">4</span></div>


<div class="viewcode-block" id="WeightShareTransform"><a class="viewcode-back" href="../../../api-docs/nemo.html#nemo.core.neural_modules.WeightShareTransform">[docs]</a><span class="k">class</span> <span class="nc">WeightShareTransform</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;When sharing parameters, what kind of transform to apply.&quot;&quot;&quot;</span>

    <span class="n">SAME</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">TRANSPOSE</span> <span class="o">=</span> <span class="mi">1</span></div>


<span class="n">PretrainedModelInfo</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span>
    <span class="s2">&quot;PretrainedModleInfo&quot;</span><span class="p">,</span> <span class="p">(</span><span class="s2">&quot;pretrained_model_name&quot;</span><span class="p">,</span> <span class="s2">&quot;description&quot;</span><span class="p">,</span> <span class="s2">&quot;parameters&quot;</span><span class="p">,</span> <span class="s2">&quot;location&quot;</span><span class="p">),</span>
<span class="p">)</span>


<div class="viewcode-block" id="NeuralModule"><a class="viewcode-back" href="../../../api-docs/nemo.html#nemo.core.neural_modules.NeuralModule">[docs]</a><span class="k">class</span> <span class="nc">NeuralModule</span><span class="p">(</span><span class="n">NeuralInterface</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstract class that every Neural Module must inherit from.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># Initialize the inferface.</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Retrieve dictionary of parameters (keys, values) passed to init.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__extract_init_params</span><span class="p">()</span>

        <span class="c1"># Get object UUID.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">())</span>

        <span class="c1"># Register module and store the generated name.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_app_state</span><span class="o">.</span><span class="n">register_module</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>

        <span class="c1"># Set &quot;module&quot; type as default.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_type</span> <span class="o">=</span> <span class="n">ModuleType</span><span class="o">.</span><span class="n">module</span>

        <span class="c1"># Set &quot;both&quot; as default operation mode.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_operation_mode</span> <span class="o">=</span> <span class="n">OperationMode</span><span class="o">.</span><span class="n">both</span>

        <span class="c1"># Get default factory.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_factory</span> <span class="o">=</span> <span class="n">NeuralModuleFactory</span><span class="o">.</span><span class="n">get_default_factory</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_factory</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NameError</span><span class="p">(</span>
                <span class="s2">&quot;A Neural Module was instantiated without first creating a Neural Factory. Please instantiate the &quot;</span>
                <span class="s2">&quot;NeuralModuleFactory class first.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Set module properties from factory else use defaults</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_placement</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_factory</span><span class="o">.</span><span class="n">placement</span>
        <span class="c1"># If one needs to change that should override it manually.</span>

        <span class="c1"># Optimization level.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_opt_level</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_factory</span><span class="o">.</span><span class="n">optim_level</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">init_params</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Property returning parameters used to instantiate the module.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dictionary containing parameters used to instantiate the module.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_params</span>

    <span class="k">def</span> <span class="nf">__extract_init_params</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Retrieves the dictionary of of parameters (keys, values) passed to constructor of a class derived</span>
<span class="sd">        (also indirectly) from the Neural Module class.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dictionary containing parameters passed to init().</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Get names of arguments of the original module init method.</span>
        <span class="n">to_set_params</span> <span class="o">=</span> <span class="n">getfullargspec</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">)</span><span class="o">.</span><span class="n">args</span>
        <span class="n">to_set_params</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s2">&quot;self&quot;</span><span class="p">)</span>

        <span class="c1"># Create empty list of init params.</span>
        <span class="n">init_params</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># Get the frame &quot;call context&quot;.</span>
        <span class="k">for</span> <span class="n">frame</span> <span class="ow">in</span> <span class="n">stack</span><span class="p">()[</span><span class="mi">1</span><span class="p">:]:</span>
            <span class="c1"># Get the current call arguments.</span>
            <span class="n">localvars</span> <span class="o">=</span> <span class="n">getargvalues</span><span class="p">(</span><span class="n">frame</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

            <span class="c1"># Fill the parameters with call arguments.</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">to_set_params</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">localvars</span><span class="o">.</span><span class="n">args</span><span class="p">:</span>
                    <span class="n">init_params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">localvars</span><span class="o">.</span><span class="n">locals</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>

            <span class="c1"># Remove all set keys.</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">init_params</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">to_set_params</span><span class="p">:</span>
                    <span class="n">to_set_params</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

            <span class="c1"># Check if we have set everything.</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">to_set_params</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">break</span>

        <span class="c1"># Make sure that we collected ALL (and ONLY) the signature params - if not, then there is a BUG!</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">to_set_params</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Could not collect all the signature params! &quot;</span>
                <span class="n">f</span><span class="s2">&quot;Please file a bug on GitHub with the current stack trace so that it can be reproduced.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># print(&quot;! init_params of {}: {}\n&quot;.format(type(self).__name__, init_params))</span>

        <span class="c1"># Return parameters.</span>
        <span class="k">return</span> <span class="n">init_params</span>

    <span class="k">def</span> <span class="nf">__validate_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Checks whether dictionary contains parameters being primitive types (string, int, float etc.)</span>
<span class="sd">        or (lists of)+ primitive types.</span>

<span class="sd">        Args:</span>
<span class="sd">            params: dictionary of parameters.</span>
<span class="sd">        Returns:</span>
<span class="sd">            True if all parameters were ok, False otherwise.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ok</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># Iterate over parameters and check them one by one.</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">variable</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">__is_of_allowed_type</span><span class="p">(</span><span class="n">variable</span><span class="p">):</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;Parameter &#39;</span><span class="si">{}</span><span class="s2">&#39; contains a variable &#39;</span><span class="si">{}</span><span class="s2">&#39; of type &#39;</span><span class="si">{}</span><span class="s2">&#39; which is not allowed.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="n">key</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>
                    <span class="p">)</span>
                <span class="p">)</span>
                <span class="n">ok</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># Return the result.</span>
        <span class="k">return</span> <span class="n">ok</span>

    <span class="k">def</span> <span class="nf">__is_of_allowed_type</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">var</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A recursive function that checks if a given variable is of allowed type.</span>

<span class="sd">        Args:</span>
<span class="sd">            pretrained_model_name (str): name of pretrained model to use in order.</span>
<span class="sd">        Returns:</span>
<span class="sd">            True if all parameters were ok, False otherwise.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Special case: None is also allowed.</span>
        <span class="k">if</span> <span class="n">var</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>

        <span class="n">var_type</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>

        <span class="c1"># If this is list - check its elements.</span>
        <span class="k">if</span> <span class="n">var_type</span> <span class="o">==</span> <span class="nb">list</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">list_var</span> <span class="ow">in</span> <span class="n">var</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">__is_of_allowed_type</span><span class="p">(</span><span class="n">list_var</span><span class="p">):</span>
                    <span class="k">return</span> <span class="kc">False</span>

        <span class="c1"># If this is dict - check its elements.</span>
        <span class="k">elif</span> <span class="n">var_type</span> <span class="o">==</span> <span class="nb">dict</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">dict_var</span> <span class="ow">in</span> <span class="n">var</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">__is_of_allowed_type</span><span class="p">(</span><span class="n">dict_var</span><span class="p">):</span>
                    <span class="k">return</span> <span class="kc">False</span>

        <span class="k">elif</span> <span class="n">var_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="c1"># Well, seems that everything is ok.</span>
        <span class="k">return</span> <span class="kc">True</span>

<div class="viewcode-block" id="NeuralModule.export_to_config"><a class="viewcode-back" href="../../../api-docs/nemo.html#nemo.core.neural_modules.NeuralModule.export_to_config">[docs]</a>    <span class="k">def</span> <span class="nf">export_to_config</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config_file</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A function that exports module &quot;configuration&quot; (i.e. init parameters) to a YAML file.</span>

<span class="sd">        Args:</span>
<span class="sd">            config_file: path (absolute or relative) and name of the config file (YML)</span>
<span class="sd">        Raises:</span>
<span class="sd">            ValueError: An error occurred and  parameters coudn&#39;t be exported.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Greate an absolute path.</span>
        <span class="n">abs_path_file</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="n">config_file</span><span class="p">)</span>

        <span class="c1"># Serialize the module.</span>
        <span class="n">to_export</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">serialize</span><span class="p">()</span>

        <span class="c1"># All parameters are ok, let&#39;s export.</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">abs_path_file</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">outfile</span><span class="p">:</span>
            <span class="n">YAML</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">to_export</span><span class="p">,</span> <span class="n">outfile</span><span class="p">)</span>

        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot;Configuration of module `</span><span class="si">{}</span><span class="s2">` (</span><span class="si">{}</span><span class="s2">) exported to &#39;</span><span class="si">{}</span><span class="s2">&#39;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">abs_path_file</span><span class="p">)</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="NeuralModule.serialize"><a class="viewcode-back" href="../../../api-docs/nemo.html#nemo.core.neural_modules.NeuralModule.serialize">[docs]</a>    <span class="k">def</span> <span class="nf">serialize</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A method serializing the whole Neural module (into a dictionary).</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dictionary containing a &quot;serialized&quot; module.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Create a dictionary representing the serialized object.</span>
        <span class="n">serialized_module</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># Add &quot;header&quot; with module &quot;specification&quot;.</span>
        <span class="n">serialized_module</span><span class="p">[</span><span class="s2">&quot;header&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__serialize_header</span><span class="p">()</span>

        <span class="c1"># Add init parameters.</span>
        <span class="n">serialized_module</span><span class="p">[</span><span class="s2">&quot;init_params&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_serialize_configuration</span><span class="p">()</span>

        <span class="c1"># Return the dictionary.</span>
        <span class="k">return</span> <span class="n">serialized_module</span></div>

    <span class="k">def</span> <span class="nf">__serialize_header</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A protected method that creates a header stored later in the configuration file.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dictionary containing a header with module specification.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Get module &quot;full specification&quot;.</span>
        <span class="n">module_full_spec</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__module__</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;.&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__qualname__</span><span class="p">)</span>
        <span class="n">module_class_name</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span>
        <span class="c1"># print(module_full_spec)</span>

        <span class="c1"># Check whether module belongs to a collection.</span>
        <span class="n">spec_list</span> <span class="o">=</span> <span class="n">module_full_spec</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>

        <span class="c1"># Do not check Neural Modules from unit tests.</span>
        <span class="k">if</span> <span class="n">spec_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;tests&quot;</span><span class="p">:</span>
            <span class="c1"># Set collection variables.</span>
            <span class="n">collection_type</span> <span class="o">=</span> <span class="s2">&quot;tests&quot;</span>
            <span class="n">collection_version</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Check if component belongs to any collection</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">spec_list</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">3</span> <span class="ow">or</span> <span class="p">(</span><span class="n">spec_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="s2">&quot;nemo&quot;</span> <span class="ow">and</span> <span class="n">spec_list</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="s2">&quot;collection&quot;</span><span class="p">):</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;Module `</span><span class="si">{}</span><span class="s2">` does not belong to any collection. This won&#39;t be allowed in the next release.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="n">module_class_name</span>
                    <span class="p">)</span>
                <span class="p">)</span>
                <span class="n">collection_type</span> <span class="o">=</span> <span class="s2">&quot;unknown&quot;</span>
                <span class="n">collection_version</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Ok, set collection.</span>
                <span class="n">collection_type</span> <span class="o">=</span> <span class="n">spec_list</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
                <span class="n">collection_version</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="c1"># TODO: to be SET!</span>
                <span class="c1"># print(getattr(&quot;nemo.collections.nlp&quot;, __version__))</span>

        <span class="c1"># Create a &quot;header&quot; with module &quot;specification&quot;.</span>
        <span class="n">header</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;nemo_core_version&quot;</span><span class="p">:</span> <span class="n">nemo_version</span><span class="p">,</span>
            <span class="s2">&quot;collection_type&quot;</span><span class="p">:</span> <span class="n">collection_type</span><span class="p">,</span>
            <span class="s2">&quot;collection_version&quot;</span><span class="p">:</span> <span class="n">collection_version</span><span class="p">,</span>
            <span class="c1"># &quot;class&quot;: module_class_name, # Operating only on full_spec now.</span>
            <span class="s2">&quot;full_spec&quot;</span><span class="p">:</span> <span class="n">module_full_spec</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">return</span> <span class="n">header</span>

    <span class="k">def</span> <span class="nf">_serialize_configuration</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A function that serializes the module &quot;configuration (i.e. init parameters) to a dictionary.</span>

<span class="sd">        ..note:</span>
<span class="sd">            Thus functions should be overloaded when writing a custom module import/export.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A &quot;serialized&quot; dictionary with module configuration.</span>
<span class="sd">        Raises:</span>
<span class="sd">            A ValueError exception in case then parameters coudn&#39;t be exported.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Check if generic export will work.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">__validate_params</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_init_params</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Generic configuration export enables to use of parameters of primitive types (string, int, float) &quot;</span>
                <span class="n">F</span><span class="s2">&quot;or (lists of/dicts of) primitive types. Please implement your own custom `export_to_config()` and &quot;</span>
                <span class="n">F</span><span class="s2">&quot;`import_from_config()` methods for your custom Module class.&quot;</span>
            <span class="p">)</span>
        <span class="c1"># In this case configuration = init parameters.</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_params</span>

<div class="viewcode-block" id="NeuralModule.import_from_config"><a class="viewcode-back" href="../../../api-docs/nemo.html#nemo.core.neural_modules.NeuralModule.import_from_config">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">import_from_config</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span> <span class="n">config_file</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">section_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">overwrite_params</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;NeuralModule&#39;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Class method importing the configuration file.</span>
<span class="sd">        Raises an ImportError exception when config file is invalid or</span>
<span class="sd">        incompatible (when called from a particular class).</span>

<span class="sd">        Args:</span>
<span class="sd">            config_file: path (absolute or relative) and name of the config file (YML)</span>
<span class="sd">            section_name: section in the configuration file storing module configuration (optional, DEFAULT: None)</span>
<span class="sd">            name: name of the module that will overwrite the name in the `init_params` (optional, DEFAULT: None)</span>
<span class="sd">            overwrite_params: Dictionary containing parameters that will be added to or overwrite (!)</span>
<span class="sd">            the default init parameters loaded from the configuration file (the module &quot;init_params&quot; section).</span>
<span class="sd">        Returns:</span>
<span class="sd">            Instance of the created NeuralModule object.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Loading configuration of a new Neural Module from the `</span><span class="si">{}</span><span class="s2">` file&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">config_file</span><span class="p">))</span>

        <span class="c1"># Validate the content of the configuration file (its header).</span>
        <span class="n">loaded_config</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">__validate_config_file</span><span class="p">(</span><span class="n">config_file</span><span class="p">,</span> <span class="n">section_name</span><span class="p">)</span>

        <span class="c1"># &quot;Deserialize&quot; the module.</span>
        <span class="n">obj</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">deserialize</span><span class="p">(</span><span class="n">loaded_config</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">overwrite_params</span><span class="p">)</span>

        <span class="c1"># Return the new module.</span>
        <span class="k">return</span> <span class="n">obj</span></div>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">__validate_config_file</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">config_file</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">section_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Class method validating whether the config file has a proper content (sections, specification etc.).</span>
<span class="sd">        Raises an ImportError exception when config file is invalid or</span>
<span class="sd">        incompatible (when called from a particular class).</span>

<span class="sd">        Args:</span>
<span class="sd">            config_file: path (absolute or relative) and name of the config file (YML)</span>
<span class="sd">            section_name: section in the configuration file storing module configuration (optional, DEFAULT: None)</span>
<span class="sd">        Returns:</span>
<span class="sd">            A loaded configuration file (dictionary).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Greate an absolute path.</span>
        <span class="n">abs_path_file</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="n">config_file</span><span class="p">)</span>

        <span class="c1"># Open the config file.</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">abs_path_file</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">stream</span><span class="p">:</span>
            <span class="n">loaded_config</span> <span class="o">=</span> <span class="n">YAML</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">stream</span><span class="p">)</span>

        <span class="c1"># Check section.</span>
        <span class="k">if</span> <span class="n">section_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">section_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">loaded_config</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
                    <span class="s2">&quot;The loaded config `</span><span class="si">{}</span><span class="s2">` doesn&#39;t contain the indicated `</span><span class="si">{}</span><span class="s2">` section&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="n">config_file</span><span class="p">,</span> <span class="n">section_name</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="c1"># Section exists - use only it for configuration.</span>
            <span class="n">loaded_config</span> <span class="o">=</span> <span class="n">loaded_config</span><span class="p">[</span><span class="n">section_name</span><span class="p">]</span>

        <span class="c1"># Make sure that the config is valid.</span>
        <span class="k">if</span> <span class="s2">&quot;header&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">loaded_config</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;The loaded config `</span><span class="si">{}</span><span class="s2">` doesn&#39;t contain the `header` section&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">config_file</span><span class="p">))</span>

        <span class="k">if</span> <span class="s2">&quot;init_params&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">loaded_config</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s2">&quot;The loaded config `</span><span class="si">{}</span><span class="s2">` doesn&#39;t contain the `init_params` section&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">config_file</span><span class="p">))</span>

        <span class="c1"># Parse the &quot;full specification&quot;.</span>
        <span class="n">spec_list</span> <span class="o">=</span> <span class="n">loaded_config</span><span class="p">[</span><span class="s2">&quot;header&quot;</span><span class="p">][</span><span class="s2">&quot;full_spec&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>

        <span class="c1"># Check if config contains data of a compatible class.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">issubclass</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="n">__deserialize_header</span><span class="p">(</span><span class="n">loaded_config</span><span class="p">[</span><span class="s2">&quot;header&quot;</span><span class="p">]),</span> <span class="bp">cls</span><span class="p">):</span>
            <span class="n">txt</span> <span class="o">=</span> <span class="s2">&quot;The loaded file `</span><span class="si">{}</span><span class="s2">` contains configuration of &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">config_file</span><span class="p">)</span>
            <span class="n">txt</span> <span class="o">=</span> <span class="n">txt</span> <span class="o">+</span> <span class="s2">&quot;`</span><span class="si">{}</span><span class="s2">` thus cannot be used for instantiation of an object of type `</span><span class="si">{}</span><span class="s2">`&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">spec_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">cls</span><span class="o">.</span><span class="vm">__name__</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="n">txt</span><span class="p">)</span>

        <span class="c1"># Success - return configuration.</span>
        <span class="k">return</span> <span class="n">loaded_config</span>

<div class="viewcode-block" id="NeuralModule.deserialize"><a class="viewcode-back" href="../../../api-docs/nemo.html#nemo.core.neural_modules.NeuralModule.deserialize">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">deserialize</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span> <span class="n">configuration</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">overwrite_params</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;NeuralModule&#39;</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Class method instantiating the neural module object based on the configuration (dictionary).</span>

<span class="sd">        Args:</span>
<span class="sd">            configuration: Dictionary containing proper &quot;header&quot; and &quot;init_params&quot; sections.</span>

<span class="sd">            name: name of the module that will overwrite the name in the `init_params` (optional, DEFAULT: None)</span>

<span class="sd">            overwrite_params: Dictionary containing parameters that will be added to or overwrite (!)</span>
<span class="sd">            the default init parameters loaded from the configuration file (the module &quot;init_params&quot; section).</span>

<span class="sd">        Returns:</span>
<span class="sd">            Instance of the created NeuralModule object.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Deserialize header - get object class.</span>
        <span class="n">module_class</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">__deserialize_header</span><span class="p">(</span><span class="n">configuration</span><span class="p">[</span><span class="s2">&quot;header&quot;</span><span class="p">])</span>

        <span class="c1"># Update parameters with additional ones.</span>
        <span class="n">configuration</span><span class="p">[</span><span class="s2">&quot;init_params&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">overwrite_params</span><span class="p">)</span>

        <span class="c1"># Override module name in init_params using the logic:</span>
        <span class="c1">#  * section_name if not none overrides init_params.name first (skipped for now, TOTHINK!)</span>
        <span class="c1">#  * name (if None) overrides init_params.name</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">configuration</span><span class="p">[</span><span class="s2">&quot;init_params&quot;</span><span class="p">][</span><span class="s2">&quot;name&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">name</span>

        <span class="c1"># Get init parameters.</span>
        <span class="n">init_params</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_deserialize_configuration</span><span class="p">(</span><span class="n">configuration</span><span class="p">[</span><span class="s2">&quot;init_params&quot;</span><span class="p">])</span>

        <span class="c1"># Create the module instance.</span>
        <span class="n">new_module</span> <span class="o">=</span> <span class="n">module_class</span><span class="p">(</span><span class="o">**</span><span class="n">init_params</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot;Instantiated a new Neural Module named `</span><span class="si">{}</span><span class="s2">` of type `</span><span class="si">{}</span><span class="s2">`&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">new_module</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">new_module</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># Return the module instance.</span>
        <span class="k">return</span> <span class="n">new_module</span></div>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">__deserialize_header</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">serialized_header</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Method deserializes the header and extracts the module class.</span>

<span class="sd">        Args:</span>
<span class="sd">            serialized_header: Dictionary containing module header.</span>
<span class="sd">        Returns:</span>
<span class="sd">            Class of the module to be created.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Parse the &quot;full specification&quot;.</span>
        <span class="n">spec_list</span> <span class="o">=</span> <span class="n">serialized_header</span><span class="p">[</span><span class="s2">&quot;full_spec&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>

        <span class="c1"># Get module class from the &quot;full specification&quot;.</span>
        <span class="n">mod_obj</span> <span class="o">=</span> <span class="nb">__import__</span><span class="p">(</span><span class="n">spec_list</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">spec</span> <span class="ow">in</span> <span class="n">spec_list</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
            <span class="n">mod_obj</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">mod_obj</span><span class="p">,</span> <span class="n">spec</span><span class="p">)</span>

        <span class="c1"># Return &quot;class&quot;.</span>
        <span class="k">return</span> <span class="n">mod_obj</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">_deserialize_configuration</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">serialized_init_params</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A function that deserializes the module &quot;configuration (i.e. init parameters).</span>

<span class="sd">        ..note:</span>
<span class="sd">            Thus functions should be overloaded when writing a custom module import/export.</span>

<span class="sd">        Args:</span>
<span class="sd">            serialized_init_params: List of init parameters loaded from the file.</span>
<span class="sd">        Returns:</span>
<span class="sd">            A &quot;deserialized&quot; list with init parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># In this case configuration = init parameters.</span>
        <span class="k">return</span> <span class="n">serialized_init_params</span>

    <span class="nd">@property</span>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">input_ports</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">NeuralType</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns definitions of module input ports</span>

<span class="sd">        Returns:</span>
<span class="sd">          A dictionary containing module&#39;s input ports (names, NeuralTypes) mapping.</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">output_ports</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">NeuralType</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns definitions of module output ports</span>

<span class="sd">        Returns:</span>
<span class="sd">          A dictionary containing module&#39;s output ports (names, NeuralTypes) mapping.</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_disabled_deployment_input_ports</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Returns names of input ports that will not be included in an export</span>

<span class="sd">        Returns:</span>
<span class="sd">          A (set) of module&#39;s input port names that are not exportable</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">set</span><span class="p">([])</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_disabled_deployment_output_ports</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Returns names of output ports that will not be included in an export</span>

<span class="sd">        Returns:</span>
<span class="sd">          A (set) of module&#39;s output port names that are not exportable</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">set</span><span class="p">([])</span>

    <span class="k">def</span> <span class="nf">_prepare_for_deployment</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Patch the module if required to prepare for deployment</span>

<span class="sd">        Returns:</span>
<span class="sd">            (Optional) input and output example tensors</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">operation_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Returns the operation mode. &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_operation_mode</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">type</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Returns the type of module. &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_type</span>

    <span class="nd">@operation_mode</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">operation_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">operation_mode</span><span class="p">:</span> <span class="n">OperationMode</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Sets the operation mode. &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_operation_mode</span> <span class="o">=</span> <span class="n">operation_mode</span>

<div class="viewcode-block" id="NeuralModule.pretrained_storage"><a class="viewcode-back" href="../../../api-docs/nemo.html#nemo.core.neural_modules.NeuralModule.pretrained_storage">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained_storage</span><span class="p">():</span>
        <span class="k">return</span> <span class="s1">&#39;&#39;</span></div>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;This method allows objects to be called with their port names</span>

<span class="sd">        Args:</span>
<span class="sd">          kwargs: Input ports and their values. For example:</span>
<span class="sd">          ...</span>
<span class="sd">          mymodule1 = Subclass1_of_NeuralModule(...)</span>
<span class="sd">          mymodule2 = Subclass2_of_NeuralModule(...)</span>
<span class="sd">          ...</span>
<span class="sd">          out_port1, out_port2 = mymodule1(input_port1=value1,</span>
<span class="sd">          input_port2=value2,</span>
<span class="sd">          input_port3=value3)</span>
<span class="sd">          out_port11 = mymodule2(input_port1=out_port2)</span>
<span class="sd">          ...</span>

<span class="sd">        Returns:</span>
<span class="sd">          NmTensor object or tuple of NmTensor objects</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># print(&quot; Neural Module:__call__&quot;)</span>

        <span class="c1"># Set the operation mode of the outer graph.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">operation_mode</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_app_state</span><span class="o">.</span><span class="n">active_graph</span><span class="o">.</span><span class="n">operation_mode</span>
        <span class="c1"># The input and output ports definitions can potentially depend on the operation mode!</span>

        <span class="c1"># Record the operation (i.e. add a single module).</span>
        <span class="n">step_number</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_app_state</span><span class="o">.</span><span class="n">active_graph</span><span class="o">.</span><span class="n">record_step</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="c1">###### PROCESS INPUTS. ######</span>
        <span class="c1"># Iterate through all passed parameters.</span>
        <span class="k">for</span> <span class="n">port_name</span><span class="p">,</span> <span class="n">port_content</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># Make sure that passed arguments corresponds to one of the input port names.</span>
            <span class="k">if</span> <span class="n">port_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_ports</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">raise</span> <span class="n">NeuralPortNameMismatchError</span><span class="p">(</span><span class="n">port_name</span><span class="p">)</span>

            <span class="c1"># At that point the input can be one of three types:</span>
            <span class="c1"># * NeuralGraph -&gt; bind port using the default name and type.</span>
            <span class="c1"># * GraphInput -&gt; check definition, if ok bind port.</span>
            <span class="c1"># * NmTensor -&gt; check definition, add self as a &quot;consumer&quot; of a tensor (produced by other module).</span>

            <span class="c1"># Check what was actually passed.</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">port_content</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;NeuralGraph&quot;</span><span class="p">:</span>
                <span class="c1"># Make sure that port_content is the currently active graph!</span>
                <span class="k">if</span> <span class="n">port_content</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_app_state</span><span class="o">.</span><span class="n">active_graph</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ConnectionError</span><span class="p">(</span><span class="s2">&quot;Ports can be bound only by passing the active graph object!&quot;</span><span class="p">)</span>
                <span class="c1"># Create an alias so the logic will be more clear.</span>
                <span class="n">active_graph</span> <span class="o">=</span> <span class="n">port_content</span>

                <span class="c1"># This case: we are nesting one graph into another and must bind input port of one graph in another!</span>
                <span class="c1"># So generally we must &quot;copy&quot; the of thus module to graog (the inverted logic!).</span>

                <span class="c1"># Copy the port &quot;definition&quot; (i.e. is NeuralType) using the same port name.</span>
                <span class="n">active_graph</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="n">port_name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_ports</span><span class="p">[</span><span class="n">port_name</span><span class="p">]</span>

                <span class="c1"># Bind the neural graph input port, i.e. remember that a given graph port should pass data</span>
                <span class="c1"># to THIS module-port (when it finally will be connected).</span>
                <span class="n">active_graph</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="n">port_name</span><span class="p">]</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">StepModulePort</span><span class="p">(</span><span class="n">step_number</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">port_name</span><span class="p">))</span>

                <span class="c1"># Please note that there are no &quot;consumers&quot; here - this is a &quot;pure binding&quot;.</span>

            <span class="k">elif</span> <span class="nb">type</span><span class="p">(</span><span class="n">port_content</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;GraphInput&quot;</span><span class="p">:</span>

                <span class="c1"># Check if GraphInput belongs to the active graph !</span>
                <span class="n">own_port</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">for</span> <span class="n">gcontent</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_app_state</span><span class="o">.</span><span class="n">active_graph</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                    <span class="k">if</span> <span class="n">gcontent</span> <span class="ow">is</span> <span class="n">port_content</span><span class="p">:</span>
                        <span class="n">own_port</span> <span class="o">=</span> <span class="kc">True</span>
                        <span class="k">break</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">own_port</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">NeuralPortNameMismatchError</span><span class="p">(</span><span class="n">port_name</span><span class="p">)</span>

                <span class="c1"># Compare input port definition with the received definition.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">input_ports</span><span class="p">[</span><span class="n">port_name</span><span class="p">]</span><span class="o">.</span><span class="n">compare_and_raise_error</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">port_name</span><span class="p">,</span> <span class="n">port_content</span><span class="o">.</span><span class="n">ntype</span>
                <span class="p">)</span>

                <span class="c1"># Bind the neural graph input port, i.e. remember that a given graph port should pass data</span>
                <span class="c1"># to THIS module-port (when it finally will be connected).</span>
                <span class="n">port_content</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">StepModulePort</span><span class="p">(</span><span class="n">step_number</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">port_name</span><span class="p">))</span>

                <span class="c1"># Please note that there are no &quot;consumers&quot; here - this is a &quot;pure binding&quot;.</span>

            <span class="k">elif</span> <span class="nb">type</span><span class="p">(</span><span class="n">port_content</span><span class="p">)</span> <span class="ow">is</span> <span class="n">NmTensor</span><span class="p">:</span>
                <span class="c1"># Compare input port definition with the received definition.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">input_ports</span><span class="p">[</span><span class="n">port_name</span><span class="p">]</span><span class="o">.</span><span class="n">compare_and_raise_error</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">port_name</span><span class="p">,</span> <span class="n">port_content</span><span class="p">)</span>

                <span class="c1"># Ok, the goal here is to actually &quot;connect&quot;: add self (module) as &quot;consumer&quot; to the input tensor.</span>
                <span class="n">port_content</span><span class="o">.</span><span class="n">add_consumer</span><span class="p">(</span><span class="n">StepModulePort</span><span class="p">(</span><span class="n">step_number</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">port_name</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="s2">&quot;Input &#39;</span><span class="si">{}</span><span class="s2">&#39; must be of one of three types: NeuralGraph, GraphInput or NmTensor&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">port_name</span><span class="p">)</span>
                <span class="p">)</span>

        <span class="c1">###### PRODUCE OUTPUTS. ######</span>
        <span class="n">output_port_defs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_ports</span>
        <span class="c1"># Create output tensors.</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_port_defs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># Get port name and type.</span>
            <span class="n">out_name</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">output_port_defs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">out_type</span> <span class="o">=</span> <span class="n">output_port_defs</span><span class="p">[</span><span class="n">out_name</span><span class="p">]</span>

            <span class="c1"># Create a single returned tensor.</span>
            <span class="n">results</span> <span class="o">=</span> <span class="n">NmTensor</span><span class="p">(</span><span class="n">producer</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span> <span class="n">producer_args</span><span class="o">=</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">output_port_name</span><span class="o">=</span><span class="n">out_name</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="n">out_type</span><span class="p">,)</span>

            <span class="c1"># Bind the &quot;default&quot; output ports.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_app_state</span><span class="o">.</span><span class="n">active_graph</span><span class="o">.</span><span class="n">bind_outputs</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Create output tensors.</span>
            <span class="n">output_tensors</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">out_name</span><span class="p">,</span> <span class="n">out_type</span> <span class="ow">in</span> <span class="n">output_port_defs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">output_tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">NmTensor</span><span class="p">(</span><span class="n">producer</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span> <span class="n">producer_args</span><span class="o">=</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">output_port_name</span><span class="o">=</span><span class="n">out_name</span><span class="p">,</span> <span class="n">ntype</span><span class="o">=</span><span class="n">out_type</span><span class="p">,)</span>
                <span class="p">)</span>

            <span class="c1"># Create a named tuple type enabling to access outputs by attributes (e.g. out.x).</span>
            <span class="n">output_class_name</span> <span class="o">=</span> <span class="n">f</span><span class="s1">&#39;</span><span class="si">{self.__class__.__name__}</span><span class="s1">Output&#39;</span>
            <span class="n">result_type</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="n">typename</span><span class="o">=</span><span class="n">output_class_name</span><span class="p">,</span> <span class="n">field_names</span><span class="o">=</span><span class="n">output_port_defs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

            <span class="c1"># Create the returned tuple object.</span>
            <span class="n">results</span> <span class="o">=</span> <span class="n">result_type</span><span class="p">(</span><span class="o">*</span><span class="n">output_tensors</span><span class="p">)</span>

            <span class="c1"># Bind the output tensors.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_app_state</span><span class="o">.</span><span class="n">active_graph</span><span class="o">.</span><span class="n">bind_outputs</span><span class="p">(</span><span class="n">output_tensors</span><span class="p">)</span>

        <span class="c1"># Return the results.</span>
        <span class="k">return</span> <span class="n">results</span>

    <span class="k">def</span> <span class="nf">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>

<div class="viewcode-block" id="NeuralModule.get_weights"><a class="viewcode-back" href="../../../api-docs/nemo.html#nemo.core.neural_modules.NeuralModule.get_weights">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">get_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)]]:</span>
        <span class="sd">&quot;&quot;&quot;Returns NeuralModule&#39;s weights copy.</span>

<span class="sd">        Returns:</span>
<span class="sd">          Dictionary of name -&gt; (weights, trainable)&quot;&quot;&quot;</span>
        <span class="k">pass</span></div>

<div class="viewcode-block" id="NeuralModule.set_weights"><a class="viewcode-back" href="../../../api-docs/nemo.html#nemo.core.neural_modules.NeuralModule.set_weights">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">set_weights</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name2weight</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[(</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bool</span><span class="p">])],</span>
        <span class="n">name2name_and_transform</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[(</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">WeightShareTransform</span><span class="p">])]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Sets weight from given values. For every named weight in</span>
<span class="sd">        name2weight,</span>
<span class="sd">        if weight with the same name is found in the model, it will be set to</span>
<span class="sd">        found value.</span>

<span class="sd">        WARNING: This will NOT tie weights. It will copy values.</span>

<span class="sd">        If ``name2name_and_transform`` is provided then if will set weights</span>
<span class="sd">        using</span>
<span class="sd">        name mapping and transform. For example, suppose ``objec1.X = 3x5</span>
<span class="sd">        weight``.</span>
<span class="sd">        Then, if ``name2name_and_transform[&#39;X&#39;]=(&#39;Y&#39;,</span>
<span class="sd">        WeightShareTransform.TRANSPOSE)``</span>
<span class="sd">        and ``Y`` is 5x3 weight and ``name2weight[&#39;Y&#39;]=Y. Then:</span>
<span class="sd">        ``object1.set_weights(name2weight, name2name_and_transform)`` will</span>
<span class="sd">        set object1.X=transpose(Y).</span>

<span class="sd">        Args:</span>
<span class="sd">          name2weight (dict): dictionary of name to (weight, trainable).</span>
<span class="sd">          Typically this is output of get_weights method.</span>
<span class="sd">          name2name_and_transform: mapping from name -&gt; (name, transform)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span></div>

<div class="viewcode-block" id="NeuralModule.list_pretrained_models"><a class="viewcode-back" href="../../../api-docs/nemo.html#nemo.core.neural_modules.NeuralModule.list_pretrained_models">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">list_pretrained_models</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">PretrainedModelInfo</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;List all available pre-trained models (e.g. weights) for this NM.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A list of PretrainedModelInfo tuples.</span>
<span class="sd">            The pretrained_model_name field of the tuple can be used to</span>
<span class="sd">            retrieve pre-trained model&#39;s weights (pass it as</span>
<span class="sd">            pretrained_model_name argument to the module&#39;s constructor)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="NeuralModule.get_config_dict_and_checkpoint"><a class="viewcode-back" href="../../../api-docs/nemo.html#nemo.core.neural_modules.NeuralModule.get_config_dict_and_checkpoint">[docs]</a>    <span class="k">def</span> <span class="nf">get_config_dict_and_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pretrained_model_name</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;WARNING: This part is work in progress&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="NeuralModule.tie_weights_with"><a class="viewcode-back" href="../../../api-docs/nemo.html#nemo.core.neural_modules.NeuralModule.tie_weights_with">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">tie_weights_with</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">module</span><span class="p">,</span>
        <span class="n">weight_names</span><span class="o">=</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">name2name_and_transform</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[(</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">WeightShareTransform</span><span class="p">])]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Ties weights between self and module. For every weight name in</span>
<span class="sd">        weight_names, if weight with the same name is found in self, it will</span>
<span class="sd">        be tied</span>
<span class="sd">        with a same weight from ``module``.</span>

<span class="sd">        WARNING: Once weights are tied, updates to one weights&#39;s weights</span>
<span class="sd">        will affect</span>
<span class="sd">        other module&#39;s weights.</span>


<span class="sd">        If ``name2name_and_transform`` is provided then if will set weights</span>
<span class="sd">        using</span>
<span class="sd">        name mapping and transform. For example, suppose ``objec1.X = 3x5</span>
<span class="sd">        weights``</span>
<span class="sd">        and ``object2.Y = 5x3 weights``. Then these weights can be tied like</span>
<span class="sd">        this:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">          object1.tie_weights_with(object2, weight_names=[&#39;X&#39;],</span>
<span class="sd">          name2name_and_transform =</span>
<span class="sd">          { &#39;X&#39;: (&#39;Y&#39;, WeightShareTransform.TRANSPOSE)})</span>


<span class="sd">        Args:</span>
<span class="sd">            module: with which module to tie weights</span>
<span class="sd">            weight_names (List[str]): list of self weights&#39; names</span>
<span class="sd">            name2name_and_transform: mapping from name -&gt; (name, transform)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span></div>

<div class="viewcode-block" id="NeuralModule.is_trainable"><a class="viewcode-back" href="../../../api-docs/nemo.html#nemo.core.neural_modules.NeuralModule.is_trainable">[docs]</a>    <span class="k">def</span> <span class="nf">is_trainable</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Checks if NeuralModule is trainable.</span>
<span class="sd">        A NeuralModule is trainable IFF it contains at least one trainable</span>
<span class="sd">        weight</span>

<span class="sd">        Returns:</span>
<span class="sd">          True if module has trainable weights, False otherwise</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">weights</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
                <span class="k">return</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="kc">False</span></div>

<div class="viewcode-block" id="NeuralModule.save_to"><a class="viewcode-back" href="../../../api-docs/nemo.html#nemo.core.neural_modules.NeuralModule.save_to">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">save_to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Save module state to file.</span>

<span class="sd">        Args:</span>
<span class="sd">          path (string): path to while where to save.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span></div>

<div class="viewcode-block" id="NeuralModule.restore_from"><a class="viewcode-back" href="../../../api-docs/nemo.html#nemo.core.neural_modules.NeuralModule.restore_from">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">restore_from</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Restore module&#39;s state from file.</span>

<span class="sd">        Args:</span>
<span class="sd">          path (string): path to where to restore from.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span></div>

<div class="viewcode-block" id="NeuralModule.freeze"><a class="viewcode-back" href="../../../api-docs/nemo.html#nemo.core.neural_modules.NeuralModule.freeze">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">freeze</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Freeze weights</span>

<span class="sd">        Args:</span>
<span class="sd">          weights (set): set of weight names to freeze</span>
<span class="sd">          If None, all weights are freezed.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span></div>

<div class="viewcode-block" id="NeuralModule.unfreeze"><a class="viewcode-back" href="../../../api-docs/nemo.html#nemo.core.neural_modules.NeuralModule.unfreeze">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">unfreeze</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Unfreeze weights</span>

<span class="sd">        Args:</span>
<span class="sd">          weights (set): set of weight names to unfreeze</span>
<span class="sd">          If None, all weights are unfreezed.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">placement</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Module&#39;s placement. Currently CPU or GPU.</span>
<span class="sd">        DataParallel and ModelParallel will come later.</span>

<span class="sd">        Returns:</span>
<span class="sd">          (DeviceType) Device where NM&#39;s weights are located</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_placement</span>

    <span class="nd">@property</span>
    <span class="nd">@deprecated</span><span class="p">(</span><span class="n">version</span><span class="o">=</span><span class="mf">0.11</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">local_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Get module&#39;s parameters</span>

<span class="sd">        Returns:</span>
<span class="sd">          module&#39;s parameters</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_params</span>
        <span class="c1"># return self._local_parameters</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">unique_instance_id</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;A unique instance id for this object</span>

<span class="sd">        Returns:</span>
<span class="sd">          A uniq uuid which can be used to identify this object</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_uuid</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">factory</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Neural module factory which created this module</span>
<span class="sd">        Returns: NeuralModuleFactory instance or None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_factory</span>

    <span class="nd">@property</span>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">num_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Number of module&#39;s weights</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018-2020, NVIDIA

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>