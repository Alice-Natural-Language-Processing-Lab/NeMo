

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Core APIs &mdash; nemo 0.11.0b9 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="中文支持" href="../chinese/intro.html" />
    <link rel="prev" title="NeMo API" href="modules.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> nemo
          

          
          </a>

          
            
            
              <div class="version">
                0.11.0b9
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/intro.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../training.html">Fast Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../asr/intro.html">Speech Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../speaker_recognition/intro.html">Speaker Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../speech_command/intro.html">Speech Commands</a></li>
<li class="toctree-l1"><a class="reference internal" href="../voice_activity_detection/intro.html">Voice Activity Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nlp/intro.html">Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tts/intro.html">Speech Synthesis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../collections/modules.html">NeMo Collections API</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">NeMo API</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Core APIs</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#module-nemo.core.neural_types">neural_types</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-nemo.core.neural_modules">neural_modules</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-nemo.core.neural_graph">neural_graph</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-nemo.core.neural_factory">neural_factory</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-nemo.core.callbacks">callbacks</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#pytorch-backend">PyTorch BackEnd</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#module-nemo.backends.pytorch.actions">Basic actions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-nemo.backends.pytorch.nm">Classes for writing your own NMs</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-nemo.backends.pytorch.module_wrapper">Trainable Module Wrapper</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../chinese/intro.html">中文支持</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">nemo</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="modules.html">NeMo API</a> &raquo;</li>
        
      <li>Core APIs</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/api-docs/nemo.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="core-apis">
<h1>Core APIs<a class="headerlink" href="#core-apis" title="Permalink to this headline">¶</a></h1>
<div class="section" id="module-nemo.core.neural_types">
<span id="neural-types"></span><h2>neural_types<a class="headerlink" href="#module-nemo.core.neural_types" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-nemo.core.neural_modules">
<span id="neural-modules"></span><h2>neural_modules<a class="headerlink" href="#module-nemo.core.neural_modules" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="nemo.core.neural_modules.WeightShareTransform">
<em class="property">class </em><code class="sig-prename descclassname">nemo.core.neural_modules.</code><code class="sig-name descname">WeightShareTransform</code><a class="reference internal" href="../_modules/nemo/core/neural_modules.html#WeightShareTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_modules.WeightShareTransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">enum.Enum</span></code></p>
<p>When sharing parameters, what kind of transform to apply.</p>
<dl class="attribute">
<dt id="nemo.core.neural_modules.WeightShareTransform.SAME">
<code class="sig-name descname">SAME</code><em class="property"> = 0</em><a class="headerlink" href="#nemo.core.neural_modules.WeightShareTransform.SAME" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nemo.core.neural_modules.WeightShareTransform.TRANSPOSE">
<code class="sig-name descname">TRANSPOSE</code><em class="property"> = 1</em><a class="headerlink" href="#nemo.core.neural_modules.WeightShareTransform.TRANSPOSE" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nemo.core.neural_modules.NeuralModule">
<em class="property">class </em><code class="sig-prename descclassname">nemo.core.neural_modules.</code><code class="sig-name descname">NeuralModule</code><span class="sig-paren">(</span><em class="sig-param">name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_modules.html#NeuralModule"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_modules.NeuralModule" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.core.neural_interface.NeuralInterface</span></code></p>
<p>Abstract class that every Neural Module must inherit from.</p>
<dl class="method">
<dt id="nemo.core.neural_modules.NeuralModule.deserialize">
<em class="property">classmethod </em><code class="sig-name descname">deserialize</code><span class="sig-paren">(</span><em class="sig-param">configuration: Dict[str, Any], name: str = None, overwrite_params: Dict[str, Any] = {}</em><span class="sig-paren">)</span> &#x2192; nemo.core.neural_modules.NeuralModule<a class="reference internal" href="../_modules/nemo/core/neural_modules.html#NeuralModule.deserialize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_modules.NeuralModule.deserialize" title="Permalink to this definition">¶</a></dt>
<dd><p>Class method instantiating the neural module object based on the configuration (dictionary).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>configuration</strong> – Dictionary containing proper “header” and “init_params” sections.</p></li>
<li><p><strong>name</strong> – name of the module that will overwrite the name in the <cite>init_params</cite> (optional, DEFAULT: None)</p></li>
<li><p><strong>overwrite_params</strong> – Dictionary containing parameters that will be added to or overwrite (!)</p></li>
<li><p><strong>default init parameters loaded from the configuration file</strong> (<em>the</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Instance of the created NeuralModule object.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_modules.NeuralModule.export_to_config">
<code class="sig-name descname">export_to_config</code><span class="sig-paren">(</span><em class="sig-param">config_file: str</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_modules.html#NeuralModule.export_to_config"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_modules.NeuralModule.export_to_config" title="Permalink to this definition">¶</a></dt>
<dd><p>A function that exports module “configuration” (i.e. init parameters) to a YAML file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>config_file</strong> – path (absolute or relative) and name of the config file (YML)</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>ValueError</strong> – An error occurred and  parameters coudn’t be exported.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_modules.NeuralModule.factory">
<em class="property">property </em><code class="sig-name descname">factory</code><a class="headerlink" href="#nemo.core.neural_modules.NeuralModule.factory" title="Permalink to this definition">¶</a></dt>
<dd><p>Neural module factory which created this module
Returns: NeuralModuleFactory instance or None</p>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_modules.NeuralModule.freeze">
<em class="property">abstract </em><code class="sig-name descname">freeze</code><span class="sig-paren">(</span><em class="sig-param">weights: Set[str] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_modules.html#NeuralModule.freeze"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_modules.NeuralModule.freeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Freeze weights</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>weights</strong> (<em>set</em>) – set of weight names to freeze</p></li>
<li><p><strong>None</strong><strong>, </strong><strong>all weights are freezed.</strong> (<em>If</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_modules.NeuralModule.get_config_dict_and_checkpoint">
<code class="sig-name descname">get_config_dict_and_checkpoint</code><span class="sig-paren">(</span><em class="sig-param">pretrained_model_name</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_modules.html#NeuralModule.get_config_dict_and_checkpoint"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_modules.NeuralModule.get_config_dict_and_checkpoint" title="Permalink to this definition">¶</a></dt>
<dd><p>WARNING: This part is work in progress</p>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_modules.NeuralModule.get_weights">
<em class="property">abstract </em><code class="sig-name descname">get_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Optional[Dict[str, bool]]<a class="reference internal" href="../_modules/nemo/core/neural_modules.html#NeuralModule.get_weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_modules.NeuralModule.get_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns NeuralModule’s weights copy.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Dictionary of name -&gt; (weights, trainable)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_modules.NeuralModule.import_from_config">
<em class="property">classmethod </em><code class="sig-name descname">import_from_config</code><span class="sig-paren">(</span><em class="sig-param">config_file: str</em>, <em class="sig-param">section_name: str = None</em>, <em class="sig-param">name: str = None</em>, <em class="sig-param">overwrite_params: Dict = {}</em><span class="sig-paren">)</span> &#x2192; nemo.core.neural_modules.NeuralModule<a class="reference internal" href="../_modules/nemo/core/neural_modules.html#NeuralModule.import_from_config"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_modules.NeuralModule.import_from_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Class method importing the configuration file.
Raises an ImportError exception when config file is invalid or
incompatible (when called from a particular class).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config_file</strong> – path (absolute or relative) and name of the config file (YML)</p></li>
<li><p><strong>section_name</strong> – section in the configuration file storing module configuration (optional, DEFAULT: None)</p></li>
<li><p><strong>name</strong> – name of the module that will overwrite the name in the <cite>init_params</cite> (optional, DEFAULT: None)</p></li>
<li><p><strong>overwrite_params</strong> – Dictionary containing parameters that will be added to or overwrite (!)</p></li>
<li><p><strong>default init parameters loaded from the configuration file</strong> (<em>the</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Instance of the created NeuralModule object.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_modules.NeuralModule.init_params">
<em class="property">property </em><code class="sig-name descname">init_params</code><a class="headerlink" href="#nemo.core.neural_modules.NeuralModule.init_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Property returning parameters used to instantiate the module.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Dictionary containing parameters used to instantiate the module.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_modules.NeuralModule.input_ports">
<em class="property">abstract property </em><code class="sig-name descname">input_ports</code><a class="headerlink" href="#nemo.core.neural_modules.NeuralModule.input_ports" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns definitions of module input ports</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A dictionary containing module’s input ports (names, NeuralTypes) mapping.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_modules.NeuralModule.is_trainable">
<code class="sig-name descname">is_trainable</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; bool<a class="reference internal" href="../_modules/nemo/core/neural_modules.html#NeuralModule.is_trainable"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_modules.NeuralModule.is_trainable" title="Permalink to this definition">¶</a></dt>
<dd><p>Checks if NeuralModule is trainable.
A NeuralModule is trainable IFF it contains at least one trainable
weight</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>True if module has trainable weights, False otherwise</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_modules.NeuralModule.list_pretrained_models">
<em class="property">static </em><code class="sig-name descname">list_pretrained_models</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Optional[List[nemo.core.neural_modules.PretrainedModleInfo]]<a class="reference internal" href="../_modules/nemo/core/neural_modules.html#NeuralModule.list_pretrained_models"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_modules.NeuralModule.list_pretrained_models" title="Permalink to this definition">¶</a></dt>
<dd><p>List all available pre-trained models (e.g. weights) for this NM.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A list of PretrainedModelInfo tuples.
The pretrained_model_name field of the tuple can be used to
retrieve pre-trained model’s weights (pass it as
pretrained_model_name argument to the module’s constructor)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_modules.NeuralModule.local_parameters">
<em class="property">property </em><code class="sig-name descname">local_parameters</code><a class="headerlink" href="#nemo.core.neural_modules.NeuralModule.local_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Get module’s parameters</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>module’s parameters</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_modules.NeuralModule.num_weights">
<em class="property">abstract property </em><code class="sig-name descname">num_weights</code><a class="headerlink" href="#nemo.core.neural_modules.NeuralModule.num_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of module’s weights</p>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_modules.NeuralModule.operation_mode">
<em class="property">property </em><code class="sig-name descname">operation_mode</code><a class="headerlink" href="#nemo.core.neural_modules.NeuralModule.operation_mode" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the operation mode.</p>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_modules.NeuralModule.output_ports">
<em class="property">abstract property </em><code class="sig-name descname">output_ports</code><a class="headerlink" href="#nemo.core.neural_modules.NeuralModule.output_ports" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns definitions of module output ports</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A dictionary containing module’s output ports (names, NeuralTypes) mapping.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_modules.NeuralModule.placement">
<em class="property">property </em><code class="sig-name descname">placement</code><a class="headerlink" href="#nemo.core.neural_modules.NeuralModule.placement" title="Permalink to this definition">¶</a></dt>
<dd><p>Module’s placement. Currently CPU or GPU.
DataParallel and ModelParallel will come later.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(DeviceType) Device where NM’s weights are located</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_modules.NeuralModule.pretrained_storage">
<em class="property">static </em><code class="sig-name descname">pretrained_storage</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_modules.html#NeuralModule.pretrained_storage"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_modules.NeuralModule.pretrained_storage" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.core.neural_modules.NeuralModule.restore_from">
<em class="property">abstract </em><code class="sig-name descname">restore_from</code><span class="sig-paren">(</span><em class="sig-param">path: str</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_modules.html#NeuralModule.restore_from"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_modules.NeuralModule.restore_from" title="Permalink to this definition">¶</a></dt>
<dd><p>Restore module’s state from file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>path</strong> (<em>string</em>) – path to where to restore from.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_modules.NeuralModule.save_to">
<em class="property">abstract </em><code class="sig-name descname">save_to</code><span class="sig-paren">(</span><em class="sig-param">path: str</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_modules.html#NeuralModule.save_to"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_modules.NeuralModule.save_to" title="Permalink to this definition">¶</a></dt>
<dd><p>Save module state to file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>path</strong> (<em>string</em>) – path to while where to save.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_modules.NeuralModule.serialize">
<code class="sig-name descname">serialize</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Dict[str, Any]<a class="reference internal" href="../_modules/nemo/core/neural_modules.html#NeuralModule.serialize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_modules.NeuralModule.serialize" title="Permalink to this definition">¶</a></dt>
<dd><p>A method serializing the whole Neural module (into a dictionary).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Dictionary containing a “serialized” module.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_modules.NeuralModule.set_weights">
<em class="property">abstract </em><code class="sig-name descname">set_weights</code><span class="sig-paren">(</span><em class="sig-param">name2weight: Dict[str, Tuple[str, bool]], name2name_and_transform: Dict[str, Tuple[str, nemo.core.neural_modules.WeightShareTransform]] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_modules.html#NeuralModule.set_weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_modules.NeuralModule.set_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets weight from given values. For every named weight in
name2weight,
if weight with the same name is found in the model, it will be set to
found value.</p>
<p>WARNING: This will NOT tie weights. It will copy values.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">name2name_and_transform</span></code> is provided then if will set weights
using
name mapping and transform. For example, suppose <code class="docutils literal notranslate"><span class="pre">objec1.X</span> <span class="pre">=</span> <span class="pre">3x5</span>
<span class="pre">weight</span></code>.
Then, if <code class="docutils literal notranslate"><span class="pre">name2name_and_transform['X']=('Y',</span>
<span class="pre">WeightShareTransform.TRANSPOSE)</span></code>
and <code class="docutils literal notranslate"><span class="pre">Y</span></code> is 5x3 weight and <code class="docutils literal notranslate"><span class="pre">name2weight['Y']=Y.</span> <span class="pre">Then:</span>
<span class="pre">``object1.set_weights(name2weight,</span> <span class="pre">name2name_and_transform)</span></code> will
set object1.X=transpose(Y).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name2weight</strong> (<em>dict</em>) – dictionary of name to (weight, trainable).</p></li>
<li><p><strong>this is output of get_weights method.</strong> (<em>Typically</em>) – </p></li>
<li><p><strong>name2name_and_transform</strong> – mapping from name -&gt; (name, transform)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_modules.NeuralModule.tie_weights_with">
<em class="property">abstract </em><code class="sig-name descname">tie_weights_with</code><span class="sig-paren">(</span><em class="sig-param">module, weight_names=typing.List[str], name2name_and_transform: Dict[str, Tuple[str, nemo.core.neural_modules.WeightShareTransform]] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_modules.html#NeuralModule.tie_weights_with"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_modules.NeuralModule.tie_weights_with" title="Permalink to this definition">¶</a></dt>
<dd><p>Ties weights between self and module. For every weight name in
weight_names, if weight with the same name is found in self, it will
be tied
with a same weight from <code class="docutils literal notranslate"><span class="pre">module</span></code>.</p>
<p>WARNING: Once weights are tied, updates to one weights’s weights
will affect
other module’s weights.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">name2name_and_transform</span></code> is provided then if will set weights
using
name mapping and transform. For example, suppose <code class="docutils literal notranslate"><span class="pre">objec1.X</span> <span class="pre">=</span> <span class="pre">3x5</span>
<span class="pre">weights</span></code>
and <code class="docutils literal notranslate"><span class="pre">object2.Y</span> <span class="pre">=</span> <span class="pre">5x3</span> <span class="pre">weights</span></code>. Then these weights can be tied like
this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">object1</span><span class="o">.</span><span class="n">tie_weights_with</span><span class="p">(</span><span class="n">object2</span><span class="p">,</span> <span class="n">weight_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">],</span>
<span class="n">name2name_and_transform</span> <span class="o">=</span>
<span class="p">{</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">WeightShareTransform</span><span class="o">.</span><span class="n">TRANSPOSE</span><span class="p">)})</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> – with which module to tie weights</p></li>
<li><p><strong>weight_names</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – list of self weights’ names</p></li>
<li><p><strong>name2name_and_transform</strong> – mapping from name -&gt; (name, transform)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_modules.NeuralModule.type">
<em class="property">property </em><code class="sig-name descname">type</code><a class="headerlink" href="#nemo.core.neural_modules.NeuralModule.type" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the type of module.</p>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_modules.NeuralModule.unfreeze">
<em class="property">abstract </em><code class="sig-name descname">unfreeze</code><span class="sig-paren">(</span><em class="sig-param">weights: Set[str] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_modules.html#NeuralModule.unfreeze"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_modules.NeuralModule.unfreeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Unfreeze weights</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>weights</strong> (<em>set</em>) – set of weight names to unfreeze</p></li>
<li><p><strong>None</strong><strong>, </strong><strong>all weights are unfreezed.</strong> (<em>If</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_modules.NeuralModule.unique_instance_id">
<em class="property">property </em><code class="sig-name descname">unique_instance_id</code><a class="headerlink" href="#nemo.core.neural_modules.NeuralModule.unique_instance_id" title="Permalink to this definition">¶</a></dt>
<dd><p>A unique instance id for this object</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A uniq uuid which can be used to identify this object</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="attribute">
<dt id="nemo.core.neural_modules.PretrainedModelInfo">
<code class="sig-prename descclassname">nemo.core.neural_modules.</code><code class="sig-name descname">PretrainedModelInfo</code><a class="headerlink" href="#nemo.core.neural_modules.PretrainedModelInfo" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.core.neural_modules.PretrainedModleInfo</span></code></p>
</dd></dl>

<dl class="class">
<dt id="nemo.core.neural_modules.ModuleType">
<em class="property">class </em><code class="sig-prename descclassname">nemo.core.neural_modules.</code><code class="sig-name descname">ModuleType</code><a class="reference internal" href="../_modules/nemo/core/neural_modules.html#ModuleType"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_modules.ModuleType" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">enum.Enum</span></code></p>
<p>Back-end independent module types</p>
<dl class="attribute">
<dt id="nemo.core.neural_modules.ModuleType.datalayer">
<code class="sig-name descname">datalayer</code><em class="property"> = 1</em><a class="headerlink" href="#nemo.core.neural_modules.ModuleType.datalayer" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nemo.core.neural_modules.ModuleType.loss">
<code class="sig-name descname">loss</code><em class="property"> = 3</em><a class="headerlink" href="#nemo.core.neural_modules.ModuleType.loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nemo.core.neural_modules.ModuleType.module">
<code class="sig-name descname">module</code><em class="property"> = 0</em><a class="headerlink" href="#nemo.core.neural_modules.ModuleType.module" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nemo.core.neural_modules.ModuleType.nontrainable">
<code class="sig-name descname">nontrainable</code><em class="property"> = 4</em><a class="headerlink" href="#nemo.core.neural_modules.ModuleType.nontrainable" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nemo.core.neural_modules.ModuleType.trainable">
<code class="sig-name descname">trainable</code><em class="property"> = 2</em><a class="headerlink" href="#nemo.core.neural_modules.ModuleType.trainable" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nemo.core.neural_modules.OperationMode">
<em class="property">class </em><code class="sig-prename descclassname">nemo.core.neural_modules.</code><code class="sig-name descname">OperationMode</code><a class="reference internal" href="../_modules/nemo/core/neural_factory.html#OperationMode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_modules.OperationMode" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">enum.Enum</span></code></p>
<p>Training or Inference (Evaluation) mode</p>
<dl class="attribute">
<dt id="nemo.core.neural_modules.OperationMode.both">
<code class="sig-name descname">both</code><em class="property"> = 2</em><a class="headerlink" href="#nemo.core.neural_modules.OperationMode.both" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nemo.core.neural_modules.OperationMode.evaluation">
<code class="sig-name descname">evaluation</code><em class="property"> = 1</em><a class="headerlink" href="#nemo.core.neural_modules.OperationMode.evaluation" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nemo.core.neural_modules.OperationMode.training">
<code class="sig-name descname">training</code><em class="property"> = 0</em><a class="headerlink" href="#nemo.core.neural_modules.OperationMode.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nemo.core.neural_graph">
<span id="neural-graph"></span><h2>neural_graph<a class="headerlink" href="#module-nemo.core.neural_graph" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="nemo.core.neural_graph.NeuralGraph">
<em class="property">class </em><code class="sig-prename descclassname">nemo.core.neural_graph.</code><code class="sig-name descname">NeuralGraph</code><span class="sig-paren">(</span><em class="sig-param">operation_mode: nemo.core.neural_factory.OperationMode = &lt;OperationMode.both: 2&gt;</em>, <em class="sig-param">name: Optional[str] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_graph.html#NeuralGraph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.core.neural_interface.NeuralInterface</span></code></p>
<p>Neural Graph class stores dynamically defined graphs of connected Neural Modules.</p>
<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.activate">
<code class="sig-name descname">activate</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_graph.html#NeuralGraph.activate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.activate" title="Permalink to this definition">¶</a></dt>
<dd><p>Activates this graph.</p>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.backward">
<code class="sig-name descname">backward</code><span class="sig-paren">(</span><em class="sig-param">losses: List[Tensor] = []</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_graph.html#NeuralGraph.backward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Backward pass through the graph. Optionally the method accepts list of losses to backpropagate from.
If not provided, will collect all output of all loss modules in the graph and backpropagate from them.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>losses</strong> – list of losses to backpropagate from (OPTIONAL, DEFAULT: [])</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>ConfigurationError if graph is non-trainable.</strong> – </p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.bind_outputs">
<code class="sig-name descname">bind_outputs</code><span class="sig-paren">(</span><em class="sig-param">tensors_list: Union[nemo.core.neural_types.neural_type.NmTensor, List[nemo.core.neural_types.neural_type.NmTensor]]</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_graph.html#NeuralGraph.bind_outputs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.bind_outputs" title="Permalink to this definition">¶</a></dt>
<dd><p>Binds the output tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tensors_list</strong> – A single tensor OR a List of tensors to be bound.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.configure_data_loader">
<code class="sig-name descname">configure_data_loader</code><span class="sig-paren">(</span><em class="sig-param">batch_size=1</em>, <em class="sig-param">shuffle=False</em>, <em class="sig-param">sampler=None</em>, <em class="sig-param">batch_sampler=None</em>, <em class="sig-param">num_workers=0</em>, <em class="sig-param">collate_fn=None</em>, <em class="sig-param">pin_memory=False</em>, <em class="sig-param">drop_last=False</em>, <em class="sig-param">timeout=0</em>, <em class="sig-param">worker_init_fn=None</em>, <em class="sig-param">multiprocessing_context=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_graph.html#NeuralGraph.configure_data_loader"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.configure_data_loader" title="Permalink to this definition">¶</a></dt>
<dd><p>Method updates the default parameters of the DataLoader used by a given neural graph.
For the details on the function/meanings of the arguments, please refer to:
<a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader</a></p>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.deactivate">
<code class="sig-name descname">deactivate</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_graph.html#NeuralGraph.deactivate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.deactivate" title="Permalink to this definition">¶</a></dt>
<dd><p>Deactivates the current graph.</p>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.deserialize">
<em class="property">classmethod </em><code class="sig-name descname">deserialize</code><span class="sig-paren">(</span><em class="sig-param">configuration: Dict[str, Any], reuse_existing_modules: bool = False, name: Optional[str] = None</em><span class="sig-paren">)</span> &#x2192; nemo.core.neural_graph.NeuralGraph<a class="reference internal" href="../_modules/nemo/core/neural_graph.html#NeuralGraph.deserialize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.deserialize" title="Permalink to this definition">¶</a></dt>
<dd><p>Class method creating a graph instance by deserializing the provided configuratino.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>configuration</strong> – Dictionary containing serialized graph.</p></li>
<li><p><strong>reuse_existing_modules</strong> – If the modules with (name, type, init_params) are already created, import will</p></li>
<li><p><strong>to them instead of creating new instances.</strong> (<em>connect</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Instance of the created NeuralGraph object.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.export_to_config">
<code class="sig-name descname">export_to_config</code><span class="sig-paren">(</span><em class="sig-param">config_file: str</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_graph.html#NeuralGraph.export_to_config"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.export_to_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Exports the neural graph to a file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>config_file</strong> – Name (and path) of the config file (YML) to be written to.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">*args: Optional[Tuple], **kwargs: Optional[Dict[str, Any]]</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_graph.html#NeuralGraph.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Graph forward method. In the execution it follows the order of the modules defined in steps and passes data
between modules following the connectivity stored in NmTensors.</p>
<p>Accepts a batch (passed as a tuple in args) OR a list of named arguments (as kwargs).</p>
<p>Use-case 1:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Retrieve batch as a tuple and pass it to forward() as tuple.</span>
<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">training_graph</span><span class="o">.</span><span class="n">get_batch</span><span class="p">():</span>
    <span class="n">training_graph</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</pre></div>
</div>
<p>Use-case 2:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Retrieve batch as a tuple and pass it to forward() as list of named arguments.</span>
<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">training_graph</span><span class="o">.</span><span class="n">get_batch</span><span class="p">():</span>
    <span class="n">training_graph</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">input1</span><span class="o">=</span><span class="n">batch</span><span class="o">.</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="o">=</span><span class="n">batch</span><span class="o">.</span><span class="n">input2</span><span class="p">)</span>
</pre></div>
</div>
<p>Use-case 3:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Retrieve batch as dictionary and pass it to forward() as list of named arguments.</span>
<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">training_graph</span><span class="o">.</span><span class="n">get_batch</span><span class="p">(</span><span class="n">yield_dict</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="n">training_graph</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>args</strong> – A tuple object (a batch) with all required inputs (optional)</p></li>
<li><p><strong>kwargs</strong> – a dictionary containing all required inputs (optional)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tuple object containing all graph outputs</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.freeze">
<code class="sig-name descname">freeze</code><span class="sig-paren">(</span><em class="sig-param">module_names: Optional[List[str]] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_graph.html#NeuralGraph.freeze"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.freeze" title="Permalink to this definition">¶</a></dt>
<dd><p>A method that freezes the weights of the trainable modules in a graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>module_names</strong> – List of modules to be frozen (Optional). If passed, all modules will be unfrozen.</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>KeyError</strong> – If name of the module won’t be recognized.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.get_batch">
<code class="sig-name descname">get_batch</code><span class="sig-paren">(</span><em class="sig-param">yield_dict: bool = False</em><span class="sig-paren">)</span> &#x2192; Union[Dict[str, Any], Tuple]<a class="reference internal" href="../_modules/nemo/core/neural_graph.html#NeuralGraph.get_batch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.get_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Method yields a single batch. Optionally, instantiates the DataLoader object used by a given graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>yield_dict</strong> – Flag used to yield a tuple or a dict - depending on the user needs</p></li>
<li><p><strong>(</strong><strong>DEFAULT</strong> – False, i.e. yielding NamedTuples)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a batch in the form of a singe namedtuple or of a dictionary.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Depending on the mode</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.import_from_config">
<em class="property">classmethod </em><code class="sig-name descname">import_from_config</code><span class="sig-paren">(</span><em class="sig-param">config_file: str</em>, <em class="sig-param">reuse_existing_modules: bool = False</em>, <em class="sig-param">overwrite_params: Dict[str</em>, <em class="sig-param">Any] = {}</em>, <em class="sig-param">name: Optional[str] = None</em><span class="sig-paren">)</span> &#x2192; nemo.core.neural_graph.NeuralGraph<a class="reference internal" href="../_modules/nemo/core/neural_graph.html#NeuralGraph.import_from_config"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.import_from_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Class method importing the neural graph from the configuration file.
Raises an ImportError exception when config file is invalid.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config_file</strong> – path (absolute or relative) and name of the config file (YML)</p></li>
<li><p><strong>reuse_existing_modules</strong> – If the modules with (name, type, init_params) are already created, import will</p></li>
<li><p><strong>to them instead of creating new instances.</strong> (<em>connect</em>) – </p></li>
<li><p><strong>overwrite_params</strong> – Dictionary containing parameters that will be added to or overwrite (!) the default</p></li>
<li><p><strong>loaded from the configuration file</strong> (<em>parameters</em>) – </p></li>
<li><p><strong>name</strong> – Name of the new graph (optional, DEFAULT: NONE)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Instance of the created NeuralGraph object.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.input_ports">
<em class="property">property </em><code class="sig-name descname">input_ports</code><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.input_ports" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns definitions of graph input ports (dict of Neural Types).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method actually returns an immutable  dictionary with port types (like Neural Modules).
In order to get access to actual graph inputs please call the inputs() method.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Graph input ports definitions.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.inputs">
<em class="property">property </em><code class="sig-name descname">inputs</code><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.inputs" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns:
Graph input.</p>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.is_complete">
<em class="property">property </em><code class="sig-name descname">is_complete</code><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.is_complete" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Property checks if graph is “complete”, which means that the graph has:</dt><dd><ul class="simple">
<li><p>exactly one DataLayer</p></li>
<li><p>zero bound input ports</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>True or false.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.is_trainable">
<em class="property">property </em><code class="sig-name descname">is_trainable</code><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.is_trainable" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Property checks if graph is “trainable”, which means that the graph:</dt><dd><ul class="simple">
<li><p>is in eval mode</p></li>
<li><p>has at least one Loss Neural Modules</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>True or false.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.modules">
<em class="property">property </em><code class="sig-name descname">modules</code><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.modules" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns modules.</p>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.named_parameters">
<code class="sig-name descname">named_parameters</code><span class="sig-paren">(</span><em class="sig-param">recurse: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_graph.html#NeuralGraph.named_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.named_parameters" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>recurse</strong> (<em>bool</em>) – if True, then yields parameters of graph modules and all their submodules.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>An iterator ovar all named parameters of all trainable components.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.operation_mode">
<em class="property">property </em><code class="sig-name descname">operation_mode</code><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.operation_mode" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns:
Operation mode.</p>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.output_ports">
<em class="property">property </em><code class="sig-name descname">output_ports</code><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.output_ports" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns definitions of module output ports (dict of Neural Types).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method actually returns an immutable dictionary with port types (like Neural Modules).
In order to get access to actual graph outpus please call the outputs() method.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Graph output ports definitions.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.output_tensors">
<em class="property">property </em><code class="sig-name descname">output_tensors</code><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.output_tensors" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns:
Fraph output tensors.</p>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.outputs">
<em class="property">property </em><code class="sig-name descname">outputs</code><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.outputs" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns graph outputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Graph outputs.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.parameters">
<code class="sig-name descname">parameters</code><span class="sig-paren">(</span><em class="sig-param">recurse: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_graph.html#NeuralGraph.parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.parameters" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>recurse</strong> (<em>bool</em>) – if True, then yields parameters of graph modules and all their submodules.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>An iterator over parameter of all trainable modules.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.record_step">
<code class="sig-name descname">record_step</code><span class="sig-paren">(</span><em class="sig-param">module: nemo.core.neural_modules.NeuralModule</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_graph.html#NeuralGraph.record_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.record_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Records the operation (the module to be executed) on a list.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>module</strong> – Neural modules added to a given graph.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Step number.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.restore_from">
<code class="sig-name descname">restore_from</code><span class="sig-paren">(</span><em class="sig-param">filename: str</em>, <em class="sig-param">module_names: Optional[List[str]] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_graph.html#NeuralGraph.restore_from"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.restore_from" title="Permalink to this definition">¶</a></dt>
<dd><p>Restores the state of trainable modules in the graph from a checkpoint file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>string</em>) – Name of the checkpoint to be restored from.</p></li>
<li><p><strong>module_names</strong> – List of modules to be frozen (Optional). If passed, all modules will be restored.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>KeyError</strong> – If name of the module won’t be recognized.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.save_to">
<code class="sig-name descname">save_to</code><span class="sig-paren">(</span><em class="sig-param">filename: str</em>, <em class="sig-param">module_names: Optional[List[str]] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_graph.html#NeuralGraph.save_to"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.save_to" title="Permalink to this definition">¶</a></dt>
<dd><p>Saves the state of trainable modules in the graph to a checkpoint file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>string</em>) – Name of the file where the checkpoint will be saved.</p></li>
<li><p><strong>module_names</strong> – List of modules to be frozen (Optional). If passed, all modules will be saved.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>KeyError</strong> – If name of the module won’t be recognized.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.serialize">
<code class="sig-name descname">serialize</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Dict[str, Any]<a class="reference internal" href="../_modules/nemo/core/neural_graph.html#NeuralGraph.serialize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.serialize" title="Permalink to this definition">¶</a></dt>
<dd><p>Method serializes the whole graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Dictionary containing description of the whole graph.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.step_number">
<em class="property">property </em><code class="sig-name descname">step_number</code><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.step_number" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns:
The current step number.</p>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.steps">
<em class="property">property </em><code class="sig-name descname">steps</code><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.steps" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns:
Dictionary [steps_number, module_name]</p>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.summary">
<code class="sig-name descname">summary</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; str<a class="reference internal" href="../_modules/nemo/core/neural_graph.html#NeuralGraph.summary"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.summary" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A nice, full graph summary.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.tensor_list">
<em class="property">property </em><code class="sig-name descname">tensor_list</code><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.tensor_list" title="Permalink to this definition">¶</a></dt>
<dd><p>Property returning output tensors by extracting them on the fly from the bound outputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>List of tensors.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.tensors">
<em class="property">property </em><code class="sig-name descname">tensors</code><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.tensors" title="Permalink to this definition">¶</a></dt>
<dd><p>Property returning a (double) dictionary of all output tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Dictionary of tensors in the format [module_name][output_port_name].</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.to">
<code class="sig-name descname">to</code><span class="sig-paren">(</span><em class="sig-param">device_type: nemo.core.neural_factory.DeviceType</em>, <em class="sig-param">use_dataparallel: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_graph.html#NeuralGraph.to"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.to" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves the all the (trainable) modules belonging to a given graph to indicated device.</p>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_graph.NeuralGraph.unfreeze">
<code class="sig-name descname">unfreeze</code><span class="sig-paren">(</span><em class="sig-param">module_names: Optional[List[str]] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_graph.html#NeuralGraph.unfreeze"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_graph.NeuralGraph.unfreeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Unfreezes weights of the trainable modules in a graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>module_names</strong> – List of modules to be unfrozen (Optional). If not passed, all modules will be unfrozen.</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>KeyError</strong> – If name of the module won’t be recognized.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nemo.core.neural_factory">
<span id="neural-factory"></span><h2>neural_factory<a class="headerlink" href="#module-nemo.core.neural_factory" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="nemo.core.neural_factory.OperationMode">
<em class="property">class </em><code class="sig-prename descclassname">nemo.core.neural_factory.</code><code class="sig-name descname">OperationMode</code><a class="reference internal" href="../_modules/nemo/core/neural_factory.html#OperationMode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_factory.OperationMode" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">enum.Enum</span></code></p>
<p>Training or Inference (Evaluation) mode</p>
<dl class="attribute">
<dt id="nemo.core.neural_factory.OperationMode.both">
<code class="sig-name descname">both</code><em class="property"> = 2</em><a class="headerlink" href="#nemo.core.neural_factory.OperationMode.both" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nemo.core.neural_factory.OperationMode.evaluation">
<code class="sig-name descname">evaluation</code><em class="property"> = 1</em><a class="headerlink" href="#nemo.core.neural_factory.OperationMode.evaluation" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nemo.core.neural_factory.OperationMode.training">
<code class="sig-name descname">training</code><em class="property"> = 0</em><a class="headerlink" href="#nemo.core.neural_factory.OperationMode.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nemo.core.neural_factory.Optimization">
<em class="property">class </em><code class="sig-prename descclassname">nemo.core.neural_factory.</code><code class="sig-name descname">Optimization</code><a class="reference internal" href="../_modules/nemo/core/neural_factory.html#Optimization"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_factory.Optimization" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">enum.Enum</span></code></p>
<p>Various levels of Apex/amp Optimization.
WARNING: This might have effect on model accuracy.</p>
<dl class="attribute">
<dt id="nemo.core.neural_factory.Optimization.mxprO0">
<code class="sig-name descname">mxprO0</code><em class="property"> = 0</em><a class="headerlink" href="#nemo.core.neural_factory.Optimization.mxprO0" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nemo.core.neural_factory.Optimization.mxprO1">
<code class="sig-name descname">mxprO1</code><em class="property"> = 1</em><a class="headerlink" href="#nemo.core.neural_factory.Optimization.mxprO1" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nemo.core.neural_factory.Optimization.mxprO2">
<code class="sig-name descname">mxprO2</code><em class="property"> = 2</em><a class="headerlink" href="#nemo.core.neural_factory.Optimization.mxprO2" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nemo.core.neural_factory.Optimization.mxprO3">
<code class="sig-name descname">mxprO3</code><em class="property"> = 3</em><a class="headerlink" href="#nemo.core.neural_factory.Optimization.mxprO3" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nemo.core.neural_factory.DeviceType">
<em class="property">class </em><code class="sig-prename descclassname">nemo.core.neural_factory.</code><code class="sig-name descname">DeviceType</code><a class="reference internal" href="../_modules/nemo/core/neural_factory.html#DeviceType"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_factory.DeviceType" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">enum.Enum</span></code></p>
<p>Device types where Neural Modules can be placed.</p>
<dl class="attribute">
<dt id="nemo.core.neural_factory.DeviceType.AllGpu">
<code class="sig-name descname">AllGpu</code><em class="property"> = 3</em><a class="headerlink" href="#nemo.core.neural_factory.DeviceType.AllGpu" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nemo.core.neural_factory.DeviceType.CPU">
<code class="sig-name descname">CPU</code><em class="property"> = 2</em><a class="headerlink" href="#nemo.core.neural_factory.DeviceType.CPU" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nemo.core.neural_factory.DeviceType.GPU">
<code class="sig-name descname">GPU</code><em class="property"> = 1</em><a class="headerlink" href="#nemo.core.neural_factory.DeviceType.GPU" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nemo.core.neural_factory.NeuralModuleFactory">
<em class="property">class </em><code class="sig-prename descclassname">nemo.core.neural_factory.</code><code class="sig-name descname">NeuralModuleFactory</code><span class="sig-paren">(</span><em class="sig-param">local_rank=None</em>, <em class="sig-param">optimization_level=&lt;Optimization.mxprO0: 0&gt;</em>, <em class="sig-param">placement=None</em>, <em class="sig-param">cudnn_benchmark=False</em>, <em class="sig-param">random_seed=None</em>, <em class="sig-param">set_default=True</em>, <em class="sig-param">log_dir=None</em>, <em class="sig-param">checkpoint_dir=None</em>, <em class="sig-param">tensorboard_dir=None</em>, <em class="sig-param">create_tb_writer=False</em>, <em class="sig-param">files_to_copy=None</em>, <em class="sig-param">add_time_to_log_dir=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_factory.html#NeuralModuleFactory"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_factory.NeuralModuleFactory" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="method">
<dt id="nemo.core.neural_factory.NeuralModuleFactory.checkpoint_dir">
<em class="property">property </em><code class="sig-name descname">checkpoint_dir</code><a class="headerlink" href="#nemo.core.neural_factory.NeuralModuleFactory.checkpoint_dir" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.core.neural_factory.NeuralModuleFactory.clear_cache">
<code class="sig-name descname">clear_cache</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_factory.html#NeuralModuleFactory.clear_cache"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_factory.NeuralModuleFactory.clear_cache" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper function to clean inference cache.</p>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_factory.NeuralModuleFactory.create_optimizer">
<code class="sig-name descname">create_optimizer</code><span class="sig-paren">(</span><em class="sig-param">optimizer</em>, <em class="sig-param">things_to_optimize</em>, <em class="sig-param">optimizer_params</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_factory.html#NeuralModuleFactory.create_optimizer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_factory.NeuralModuleFactory.create_optimizer" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.core.neural_factory.NeuralModuleFactory.deployment_export">
<code class="sig-name descname">deployment_export</code><span class="sig-paren">(</span><em class="sig-param">module</em>, <em class="sig-param">output: str</em>, <em class="sig-param">d_format: nemo.core.neural_factory.DeploymentFormat</em>, <em class="sig-param">input_example=None</em>, <em class="sig-param">output_example=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_factory.html#NeuralModuleFactory.deployment_export"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_factory.NeuralModuleFactory.deployment_export" title="Permalink to this definition">¶</a></dt>
<dd><p>Exports Neural Module instance for deployment.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> – neural module to export</p></li>
<li><p><strong>output</strong> (<em>str</em>) – where export results should be saved</p></li>
<li><p><strong>d_format</strong> (<a class="reference internal" href="#nemo.core.neural_factory.DeploymentFormat" title="nemo.core.neural_factory.DeploymentFormat"><em>DeploymentFormat</em></a>) – which deployment format to use</p></li>
<li><p><strong>input_example</strong> – sometimes tracing will require input examples</p></li>
<li><p><strong>output_example</strong> – Should match inference on input_example</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_factory.NeuralModuleFactory.eval">
<code class="sig-name descname">eval</code><span class="sig-paren">(</span><em class="sig-param">callbacks: List[nemo.core.deprecated_callbacks.EvaluatorCallback]</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_factory.html#NeuralModuleFactory.eval"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_factory.NeuralModuleFactory.eval" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.core.neural_factory.NeuralModuleFactory.get_default_factory">
<em class="property">classmethod </em><code class="sig-name descname">get_default_factory</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_factory.html#NeuralModuleFactory.get_default_factory"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_factory.NeuralModuleFactory.get_default_factory" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.core.neural_factory.NeuralModuleFactory.global_rank">
<em class="property">property </em><code class="sig-name descname">global_rank</code><a class="headerlink" href="#nemo.core.neural_factory.NeuralModuleFactory.global_rank" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.core.neural_factory.NeuralModuleFactory.infer">
<code class="sig-name descname">infer</code><span class="sig-paren">(</span><em class="sig-param">tensors: List[nemo.core.neural_types.neural_type.NmTensor], checkpoint_dir=None, ckpt_pattern='', verbose=True, cache=False, use_cache=False, offload_to_cpu=True, modules_to_restore=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_factory.html#NeuralModuleFactory.infer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_factory.NeuralModuleFactory.infer" title="Permalink to this definition">¶</a></dt>
<dd><p>Runs inference to obtain values for tensors</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensors</strong> (<em>list</em><em>[</em><em>NmTensor</em><em>]</em>) – List of NeMo tensors that we want to get
values of.</p></li>
<li><p><strong>checkpoint_dir</strong> (<em>str</em>) – Path to checkpoint directory. Default is None
which does not load checkpoints.</p></li>
<li><p><strong>ckpt_pattern</strong> (<em>str</em>) – Pattern used to check for checkpoints inside
checkpoint_dir. Default is ‘’ which matches any checkpoints
inside checkpoint_dir.</p></li>
<li><p><strong>verbose</strong> (<em>bool</em>) – Controls printing. Defaults to True.</p></li>
<li><p><strong>cache</strong> (<em>bool</em>) – If True, cache all <cite>tensors</cite> and intermediate tensors
so that future calls that have use_cache set will avoid
computation. Defaults to False.</p></li>
<li><p><strong>use_cache</strong> (<em>bool</em>) – Values from <cite>tensors</cite> will be always re-computed.
It will re-use intermediate tensors from the DAG leading to
<cite>tensors</cite>. If you want something to be re-computed, put it into
<cite>tensors</cite> list. Defaults to False.</p></li>
<li><p><strong>offload_to_cpu</strong> (<em>bool</em>) – If True, all evaluated tensors are moved to
cpu memory after each inference batch. Defaults to True.</p></li>
<li><p><strong>modules_to_restore</strong> (<em>list</em>) – Defaults to None, in which case all
NMs inside callchain with weights will be restored. If
specified only the modules inside this list will be restored.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of evaluated tensors. Each element in the list is also a list
where each element is now a batch of tensor values.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_factory.NeuralModuleFactory.optim_level">
<em class="property">property </em><code class="sig-name descname">optim_level</code><a class="headerlink" href="#nemo.core.neural_factory.NeuralModuleFactory.optim_level" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.core.neural_factory.NeuralModuleFactory.placement">
<em class="property">property </em><code class="sig-name descname">placement</code><a class="headerlink" href="#nemo.core.neural_factory.NeuralModuleFactory.placement" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.core.neural_factory.NeuralModuleFactory.reset_default_factory">
<em class="property">classmethod </em><code class="sig-name descname">reset_default_factory</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_factory.html#NeuralModuleFactory.reset_default_factory"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_factory.NeuralModuleFactory.reset_default_factory" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.core.neural_factory.NeuralModuleFactory.reset_trainer">
<code class="sig-name descname">reset_trainer</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_factory.html#NeuralModuleFactory.reset_trainer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_factory.NeuralModuleFactory.reset_trainer" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.core.neural_factory.NeuralModuleFactory.set_default_factory">
<em class="property">classmethod </em><code class="sig-name descname">set_default_factory</code><span class="sig-paren">(</span><em class="sig-param">factory</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_factory.html#NeuralModuleFactory.set_default_factory"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_factory.NeuralModuleFactory.set_default_factory" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.core.neural_factory.NeuralModuleFactory.sync_all_processes">
<code class="sig-name descname">sync_all_processes</code><span class="sig-paren">(</span><em class="sig-param">status=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_factory.html#NeuralModuleFactory.sync_all_processes"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_factory.NeuralModuleFactory.sync_all_processes" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper function for testing that allows proccess 0 to inform all
other processes of failures. Does nothing if not using distributed
training. Usage example can be seen in examples/asr/jasper_an4.py</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>status</strong> (<em>bool</em>) – Defaults to True. If any proccess passes False, it
will trigger a graceful exit on all other processes. It is
assumed that the process that passed False will print an error
message on its own and exit</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.core.neural_factory.NeuralModuleFactory.tb_writer">
<em class="property">property </em><code class="sig-name descname">tb_writer</code><a class="headerlink" href="#nemo.core.neural_factory.NeuralModuleFactory.tb_writer" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.core.neural_factory.NeuralModuleFactory.train">
<code class="sig-name descname">train</code><span class="sig-paren">(</span><em class="sig-param">tensors_to_optimize=None</em>, <em class="sig-param">training_graph=None</em>, <em class="sig-param">optimizer=None</em>, <em class="sig-param">optimization_params=None</em>, <em class="sig-param">callbacks: Optional[List[Union[nemo.core.deprecated_callbacks.ActionCallback</em>, <em class="sig-param">nemo.core.callbacks.NeMoCallback]]] = None</em>, <em class="sig-param">lr_policy=None</em>, <em class="sig-param">batches_per_step=None</em>, <em class="sig-param">stop_on_nan_loss=False</em>, <em class="sig-param">synced_batchnorm=False</em>, <em class="sig-param">synced_batchnorm_groupsize=0</em>, <em class="sig-param">gradient_predivide=False</em>, <em class="sig-param">amp_max_loss_scale=16777216.0</em>, <em class="sig-param">reset=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/neural_factory.html#NeuralModuleFactory.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_factory.NeuralModuleFactory.train" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.core.neural_factory.NeuralModuleFactory.work_dir">
<em class="property">property </em><code class="sig-name descname">work_dir</code><a class="headerlink" href="#nemo.core.neural_factory.NeuralModuleFactory.work_dir" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.core.neural_factory.NeuralModuleFactory.world_size">
<em class="property">property </em><code class="sig-name descname">world_size</code><a class="headerlink" href="#nemo.core.neural_factory.NeuralModuleFactory.world_size" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nemo.core.neural_factory.DeploymentFormat">
<em class="property">class </em><code class="sig-prename descclassname">nemo.core.neural_factory.</code><code class="sig-name descname">DeploymentFormat</code><a class="reference internal" href="../_modules/nemo/core/neural_factory.html#DeploymentFormat"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.neural_factory.DeploymentFormat" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">enum.Enum</span></code></p>
<p>Which format to use when exporting a Neural Module for deployment</p>
<dl class="attribute">
<dt id="nemo.core.neural_factory.DeploymentFormat.AUTO">
<code class="sig-name descname">AUTO</code><em class="property"> = 0</em><a class="headerlink" href="#nemo.core.neural_factory.DeploymentFormat.AUTO" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nemo.core.neural_factory.DeploymentFormat.JARVIS">
<code class="sig-name descname">JARVIS</code><em class="property"> = 5</em><a class="headerlink" href="#nemo.core.neural_factory.DeploymentFormat.JARVIS" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nemo.core.neural_factory.DeploymentFormat.ONNX">
<code class="sig-name descname">ONNX</code><em class="property"> = 3</em><a class="headerlink" href="#nemo.core.neural_factory.DeploymentFormat.ONNX" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nemo.core.neural_factory.DeploymentFormat.PYTORCH">
<code class="sig-name descname">PYTORCH</code><em class="property"> = 1</em><a class="headerlink" href="#nemo.core.neural_factory.DeploymentFormat.PYTORCH" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nemo.core.neural_factory.DeploymentFormat.TORCHSCRIPT">
<code class="sig-name descname">TORCHSCRIPT</code><em class="property"> = 2</em><a class="headerlink" href="#nemo.core.neural_factory.DeploymentFormat.TORCHSCRIPT" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nemo.core.neural_factory.DeploymentFormat.TRTONNX">
<code class="sig-name descname">TRTONNX</code><em class="property"> = 4</em><a class="headerlink" href="#nemo.core.neural_factory.DeploymentFormat.TRTONNX" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nemo.core.callbacks">
<span id="callbacks"></span><h2>callbacks<a class="headerlink" href="#module-nemo.core.callbacks" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="nemo.core.callbacks.CheckpointCallback">
<em class="property">class </em><code class="sig-prename descclassname">nemo.core.callbacks.</code><code class="sig-name descname">CheckpointCallback</code><span class="sig-paren">(</span><em class="sig-param">folder: str</em>, <em class="sig-param">load_from_folder: str = None</em>, <em class="sig-param">step_freq: int = -1</em>, <em class="sig-param">epoch_freq: int = -1</em>, <em class="sig-param">checkpoints_to_keep: int = 4</em>, <em class="sig-param">force_load: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#CheckpointCallback"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.CheckpointCallback" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nemo.core.callbacks.NeMoCallback" title="nemo.core.callbacks.NeMoCallback"><code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.core.callbacks.NeMoCallback</span></code></a></p>
<p>A callback that does checkpointing of module weights and trainer (incl. optimizer) status.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>folder</strong> (<em>str</em><em>, </em><em>required</em>) – A path where checkpoints are to be stored and loaded from if load_from_folder is
None.</p></li>
<li><p><strong>load_from_folder</strong> (<em>str</em>) – A path where checkpoints can be loaded from.
Defaults to None.</p></li>
<li><p><strong>step_freq</strong> (<em>int</em>) – How often in terms of steps to save checkpoints. One of step_freq or epoch_freq is
required.</p></li>
<li><p><strong>epoch_freq</strong> (<em>int</em>) – How often in terms of epochs to save checkpoints. One of step_freq or epoch_freq is
required.</p></li>
<li><p><strong>checkpoints_to_keep</strong> (<em>int</em>) – Number of most recent checkpoints to keep. Older checkpoints will be deleted.
Defaults to 4.</p></li>
<li><p><strong>force_load</strong> (<em>bool</em>) – Whether to crash if loading is unsuccessful.
Defaults to False</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="nemo.core.callbacks.CheckpointCallback.on_action_end">
<code class="sig-name descname">on_action_end</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#CheckpointCallback.on_action_end"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.CheckpointCallback.on_action_end" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.core.callbacks.CheckpointCallback.on_action_start">
<code class="sig-name descname">on_action_start</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#CheckpointCallback.on_action_start"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.CheckpointCallback.on_action_start" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.core.callbacks.CheckpointCallback.on_epoch_end">
<code class="sig-name descname">on_epoch_end</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#CheckpointCallback.on_epoch_end"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.CheckpointCallback.on_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.core.callbacks.CheckpointCallback.on_step_end">
<code class="sig-name descname">on_step_end</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#CheckpointCallback.on_step_end"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.CheckpointCallback.on_step_end" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nemo.core.callbacks.NeMoCallback">
<em class="property">class </em><code class="sig-prename descclassname">nemo.core.callbacks.</code><code class="sig-name descname">NeMoCallback</code><a class="reference internal" href="../_modules/nemo/core/callbacks.html#NeMoCallback"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.NeMoCallback" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>The base class for callbacks inside of NeMo. It contains no __init__ which children classes are responsible for.
Each callback contains 8 functions which are called at different stages of train(). All functions must take as the
first argument: the current action state. This state is a StateWrapper object.
TODO: Add a link to documentation.</p>
<dl class="method">
<dt id="nemo.core.callbacks.NeMoCallback.on_action_end">
<code class="sig-name descname">on_action_end</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#NeMoCallback.on_action_end"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.NeMoCallback.on_action_end" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.core.callbacks.NeMoCallback.on_action_start">
<code class="sig-name descname">on_action_start</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#NeMoCallback.on_action_start"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.NeMoCallback.on_action_start" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.core.callbacks.NeMoCallback.on_batch_end">
<code class="sig-name descname">on_batch_end</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#NeMoCallback.on_batch_end"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.NeMoCallback.on_batch_end" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.core.callbacks.NeMoCallback.on_batch_start">
<code class="sig-name descname">on_batch_start</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#NeMoCallback.on_batch_start"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.NeMoCallback.on_batch_start" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.core.callbacks.NeMoCallback.on_epoch_end">
<code class="sig-name descname">on_epoch_end</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#NeMoCallback.on_epoch_end"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.NeMoCallback.on_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.core.callbacks.NeMoCallback.on_epoch_start">
<code class="sig-name descname">on_epoch_start</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#NeMoCallback.on_epoch_start"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.NeMoCallback.on_epoch_start" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.core.callbacks.NeMoCallback.on_step_end">
<code class="sig-name descname">on_step_end</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#NeMoCallback.on_step_end"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.NeMoCallback.on_step_end" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.core.callbacks.NeMoCallback.on_step_start">
<code class="sig-name descname">on_step_start</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#NeMoCallback.on_step_start"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.NeMoCallback.on_step_start" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nemo.core.callbacks.SimpleLogger">
<em class="property">class </em><code class="sig-prename descclassname">nemo.core.callbacks.</code><code class="sig-name descname">SimpleLogger</code><span class="sig-paren">(</span><em class="sig-param">step_freq: int = 100, tensors_to_log: List[Union[str, nemo.core.neural_types.neural_type.NmTensor]] = ['loss']</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#SimpleLogger"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.SimpleLogger" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nemo.core.callbacks.NeMoCallback" title="nemo.core.callbacks.NeMoCallback"><code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.core.callbacks.NeMoCallback</span></code></a></p>
<p>A simple callback that prints tensors to screen. It’s default option is to print the training loss every
100 steps. Additional tensors can be printed by adding them to the tensors_to_log argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>step_freq</strong> (<em>int</em>) – The frequency of printing to screen. Defaults to every 100 steps</p></li>
<li><p><strong>tensors_to_log</strong> (<em>List of str</em><em> or </em><em>NmTensor</em>) – A list of either tensor names or NmTensors which will be printed
every step_freq steps.
Defaults to [“loss”] which only prints the loss.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="nemo.core.callbacks.SimpleLogger.on_step_end">
<code class="sig-name descname">on_step_end</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#SimpleLogger.on_step_end"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.SimpleLogger.on_step_end" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nemo.core.callbacks.TensorboardLogger">
<em class="property">class </em><code class="sig-prename descclassname">nemo.core.callbacks.</code><code class="sig-name descname">TensorboardLogger</code><span class="sig-paren">(</span><em class="sig-param">tb_writer: torch.utils.tensorboard.SummaryWriter, step_freq: int = 100, tensors_to_log: List[Union[str, nemo.core.neural_types.neural_type.NmTensor]] = ['loss'], custom_tb_log_func: Callable[[Union[str, nemo.core.neural_types.neural_type.NmTensor]], None] = None, log_epoch: bool = True, log_lr: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#TensorboardLogger"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.TensorboardLogger" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nemo.core.callbacks.NeMoCallback" title="nemo.core.callbacks.NeMoCallback"><code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.core.callbacks.NeMoCallback</span></code></a></p>
<p>A tensorboard callback that logs tensors using a tensorboard writer object. It’s default option is to log
the loss every 100 steps. Additional scalar tensors can be logged by adding them to the tensors_to_log
argument. In order to log complex tensorboard entities, the custom_tb_log_func must be passed it. By default,
it always logs the current epoch and the time taken per epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tb_writer</strong> (<em>required</em>) – The tensorboard logger object.</p></li>
<li><p><strong>step_freq</strong> (<em>int</em>) – The frequency of tensorboard logging. Defaults to every 100 steps</p></li>
<li><p><strong>tensors_to_log</strong> (<em>List of str</em><em> or </em><em>NmTensor</em>) – A list of either tensor names or NmTensors which will be logged
every step_freq steps.
Defaults to [“loss”] which only prints the loss.</p></li>
<li><p><strong>custom_tb_log_func</strong> (<em>func</em>) – custom_tb_log_func should accept three position arguments: tensors, tb_writer, and
step. tensors is a list of pytorch tensors that correspond to the values of the NmTensors in
tensors_to_log. tb_writer is the tensorboard logger passed to TensorboardLogger. step is the current
step.
Defaults to None which logs each tensors_to_log as a scalar.</p></li>
<li><p><strong>log_epoch</strong> (<em>bool</em>) – Whether to log epoch and epoch training time to tensorboard.
Defaults to True.</p></li>
<li><p><strong>log_lr</strong> (<em>bool</em>) – Whether to log the learning rate to tensorboard.
Defaults to True.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="nemo.core.callbacks.TensorboardLogger.on_epoch_end">
<code class="sig-name descname">on_epoch_end</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#TensorboardLogger.on_epoch_end"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.TensorboardLogger.on_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.core.callbacks.TensorboardLogger.on_epoch_start">
<code class="sig-name descname">on_epoch_start</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#TensorboardLogger.on_epoch_start"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.TensorboardLogger.on_epoch_start" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.core.callbacks.TensorboardLogger.on_step_end">
<code class="sig-name descname">on_step_end</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#TensorboardLogger.on_step_end"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.TensorboardLogger.on_step_end" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nemo.core.callbacks.WandBLogger">
<em class="property">class </em><code class="sig-prename descclassname">nemo.core.callbacks.</code><code class="sig-name descname">WandBLogger</code><span class="sig-paren">(</span><em class="sig-param">step_freq: int = 100, tensors_to_log: List[Union[str, nemo.core.neural_types.neural_type.NmTensor]] = ['loss'], wandb_name: str = None, wandb_project: str = None, args=None, log_epoch: bool = True, log_lr: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#WandBLogger"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.WandBLogger" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nemo.core.callbacks.NeMoCallback" title="nemo.core.callbacks.NeMoCallback"><code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.core.callbacks.NeMoCallback</span></code></a></p>
<p>A [Weights &amp; Biases](<a class="reference external" href="https://docs.wandb.com/">https://docs.wandb.com/</a>) callback that logs tensors to W&amp;B. It’s default option is to
log the loss every 100 steps. Additional scalar tensors can be logged by adding them to the tensors_to_log
argument. By default, it always logs the current epoch and the time taken per epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>step_freq</strong> (<em>int</em>) – The frequency of Weights and Biases logging. Defaults to every 100 steps</p></li>
<li><p><strong>tensors_to_log</strong> (<em>List of str</em><em> or </em><em>NmTensor</em>) – A list of either tensor names or NmTensors which will be logged
every step_freq steps.
Defaults to [“loss”] which only prints the loss.</p></li>
<li><p><strong>wandb_name</strong> (<em>str</em>) – wandb experiment name.
Defaults to None</p></li>
<li><p><strong>wandb_project</strong> (<em>str</em>) – wandb project name.
Defaults to None</p></li>
<li><p><strong>args</strong> – argparse flags which will be logged as hyperparameters.
Defaults to None.</p></li>
<li><p><strong>log_epoch</strong> (<em>bool</em>) – Whether to log epoch and epoch training time to Weights and Biases.
Defaults to True.</p></li>
<li><p><strong>log_lr</strong> (<em>bool</em>) – Whether to log epoch and epoch training time to Weights and Biases.
Defaults to True.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="nemo.core.callbacks.WandBLogger.on_action_start">
<code class="sig-name descname">on_action_start</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#WandBLogger.on_action_start"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.WandBLogger.on_action_start" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.core.callbacks.WandBLogger.on_epoch_end">
<code class="sig-name descname">on_epoch_end</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#WandBLogger.on_epoch_end"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.WandBLogger.on_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.core.callbacks.WandBLogger.on_epoch_start">
<code class="sig-name descname">on_epoch_start</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#WandBLogger.on_epoch_start"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.WandBLogger.on_epoch_start" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.core.callbacks.WandBLogger.on_step_end">
<code class="sig-name descname">on_step_end</code><span class="sig-paren">(</span><em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#WandBLogger.on_step_end"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.WandBLogger.on_step_end" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="nemo.core.callbacks.on_action_end">
<code class="sig-prename descclassname">nemo.core.callbacks.</code><code class="sig-name descname">on_action_end</code><span class="sig-paren">(</span><em class="sig-param">func</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#on_action_end"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.on_action_end" title="Permalink to this definition">¶</a></dt>
<dd><p>A function decorator that wraps a Callable inside the NeMoCallback object and runs the function with the
on_action_end callback event.</p>
</dd></dl>

<dl class="function">
<dt id="nemo.core.callbacks.on_action_start">
<code class="sig-prename descclassname">nemo.core.callbacks.</code><code class="sig-name descname">on_action_start</code><span class="sig-paren">(</span><em class="sig-param">func</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#on_action_start"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.on_action_start" title="Permalink to this definition">¶</a></dt>
<dd><p>A function decorator that wraps a Callable inside the NeMoCallback object and runs the function with the
on_action_start callback event.</p>
</dd></dl>

<dl class="function">
<dt id="nemo.core.callbacks.on_batch_end">
<code class="sig-prename descclassname">nemo.core.callbacks.</code><code class="sig-name descname">on_batch_end</code><span class="sig-paren">(</span><em class="sig-param">func</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#on_batch_end"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.on_batch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>A function decorator that wraps a Callable inside the NeMoCallback object and runs the function with the
on_batch_end callback event.</p>
</dd></dl>

<dl class="function">
<dt id="nemo.core.callbacks.on_batch_start">
<code class="sig-prename descclassname">nemo.core.callbacks.</code><code class="sig-name descname">on_batch_start</code><span class="sig-paren">(</span><em class="sig-param">func</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#on_batch_start"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.on_batch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>A function decorator that wraps a Callable inside the NeMoCallback object and runs the function with the
on_batch_start callback event.</p>
</dd></dl>

<dl class="function">
<dt id="nemo.core.callbacks.on_epoch_end">
<code class="sig-prename descclassname">nemo.core.callbacks.</code><code class="sig-name descname">on_epoch_end</code><span class="sig-paren">(</span><em class="sig-param">func</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#on_epoch_end"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.on_epoch_end" title="Permalink to this definition">¶</a></dt>
<dd><p>A function decorator that wraps a Callable inside the NeMoCallback object and runs the function with the
on_epoch_end callback event.</p>
</dd></dl>

<dl class="function">
<dt id="nemo.core.callbacks.on_epoch_start">
<code class="sig-prename descclassname">nemo.core.callbacks.</code><code class="sig-name descname">on_epoch_start</code><span class="sig-paren">(</span><em class="sig-param">func</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#on_epoch_start"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.on_epoch_start" title="Permalink to this definition">¶</a></dt>
<dd><p>A function decorator that wraps a Callable inside the NeMoCallback object and runs the function with the
on_epoch_start callback event.</p>
</dd></dl>

<dl class="function">
<dt id="nemo.core.callbacks.on_step_end">
<code class="sig-prename descclassname">nemo.core.callbacks.</code><code class="sig-name descname">on_step_end</code><span class="sig-paren">(</span><em class="sig-param">func</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#on_step_end"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.on_step_end" title="Permalink to this definition">¶</a></dt>
<dd><p>A function decorator that wraps a Callable inside the NeMoCallback object and runs the function with the
on_step_end callback event.</p>
</dd></dl>

<dl class="function">
<dt id="nemo.core.callbacks.on_step_start">
<code class="sig-prename descclassname">nemo.core.callbacks.</code><code class="sig-name descname">on_step_start</code><span class="sig-paren">(</span><em class="sig-param">func</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/core/callbacks.html#on_step_start"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.core.callbacks.on_step_start" title="Permalink to this definition">¶</a></dt>
<dd><p>A function decorator that wraps a Callable inside the NeMoCallback object and runs the function with the
on_step_start callback event.</p>
</dd></dl>

</div>
</div>
<div class="section" id="pytorch-backend">
<h1>PyTorch BackEnd<a class="headerlink" href="#pytorch-backend" title="Permalink to this headline">¶</a></h1>
<p>Currently, we only support PyTorch backend.</p>
<div class="section" id="module-nemo.backends.pytorch.actions">
<span id="basic-actions"></span><h2>Basic actions<a class="headerlink" href="#module-nemo.backends.pytorch.actions" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="nemo.backends.pytorch.actions.PtActions">
<em class="property">class </em><code class="sig-prename descclassname">nemo.backends.pytorch.actions.</code><code class="sig-name descname">PtActions</code><span class="sig-paren">(</span><em class="sig-param">local_rank=None</em>, <em class="sig-param">global_rank=None</em>, <em class="sig-param">tb_writer=None</em>, <em class="sig-param">optimization_level=&lt;Optimization.mxprO0: 0&gt;</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/actions.html#PtActions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.actions.PtActions" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.core.actions.Actions</span></code></p>
<dl class="method">
<dt id="nemo.backends.pytorch.actions.PtActions.append_to_cache">
<code class="sig-name descname">append_to_cache</code><span class="sig-paren">(</span><em class="sig-param">registered_tensors: dict</em>, <em class="sig-param">offload_to_cpu</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/actions.html#PtActions.append_to_cache"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.actions.PtActions.append_to_cache" title="Permalink to this definition">¶</a></dt>
<dd><p>Simpler helper function to add results of __nm_graph_forward_pass to
current cache.</p>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.actions.PtActions.clear_cache">
<code class="sig-name descname">clear_cache</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/actions.html#PtActions.clear_cache"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.actions.PtActions.clear_cache" title="Permalink to this definition">¶</a></dt>
<dd><p>Simple helpful function to clear cache by setting self.cache to
None</p>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.actions.PtActions.create_optimizer">
<code class="sig-name descname">create_optimizer</code><span class="sig-paren">(</span><em class="sig-param">optimizer</em>, <em class="sig-param">things_to_optimize</em>, <em class="sig-param">optimizer_params=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/actions.html#PtActions.create_optimizer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.actions.PtActions.create_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper function around __setup_optimizer()</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> – A instantiated PyTorch optimizer or string. For
currently supported strings, see __setup_optimizer().</p></li>
<li><p><strong>things_to_optimize</strong> (<em>list</em>) – Must be a list of Neural Modules and/or
parameters. If a Neural Module is passed, all trainable
parameters are extracted and passed to the optimizer.</p></li>
<li><p><strong>optimizer_params</strong> (<em>dict</em>) – Optional parameters dictionary.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Optimizer</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.actions.PtActions.depad_tensor">
<em class="property">static </em><code class="sig-name descname">depad_tensor</code><span class="sig-paren">(</span><em class="sig-param">t: torch.Tensor</em>, <em class="sig-param">original_size: torch.Size</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/actions.html#PtActions.depad_tensor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.actions.PtActions.depad_tensor" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.actions.PtActions.deployment_export">
<em class="property">static </em><code class="sig-name descname">deployment_export</code><span class="sig-paren">(</span><em class="sig-param">module</em>, <em class="sig-param">output: str</em>, <em class="sig-param">d_format: nemo.core.neural_factory.DeploymentFormat</em>, <em class="sig-param">input_example=None</em>, <em class="sig-param">output_example=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/actions.html#PtActions.deployment_export"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.actions.PtActions.deployment_export" title="Permalink to this definition">¶</a></dt>
<dd><p>Exports Neural Module instance for deployment.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> – neural module to export</p></li>
<li><p><strong>output</strong> (<em>str</em>) – where export results should be saved</p></li>
<li><p><strong>d_format</strong> (<a class="reference internal" href="#nemo.core.neural_factory.DeploymentFormat" title="nemo.core.neural_factory.DeploymentFormat"><em>DeploymentFormat</em></a>) – which deployment format to use</p></li>
<li><p><strong>input_example</strong> – sometimes tracing will require input examples</p></li>
<li><p><strong>output_example</strong> – Should match inference on input_example</p></li>
<li><p><strong>amp_max_loss_scale</strong> (<em>float</em>) – Max value for amp loss scaling.
Defaults to 2.0**24.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.actions.PtActions.epoch">
<em class="property">property </em><code class="sig-name descname">epoch</code><a class="headerlink" href="#nemo.backends.pytorch.actions.PtActions.epoch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.actions.PtActions.epoch_num">
<em class="property">property </em><code class="sig-name descname">epoch_num</code><a class="headerlink" href="#nemo.backends.pytorch.actions.PtActions.epoch_num" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.actions.PtActions.get_DDP_modules">
<code class="sig-name descname">get_DDP_modules</code><span class="sig-paren">(</span><em class="sig-param">call_chain</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/actions.html#PtActions.get_DDP_modules"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.actions.PtActions.get_DDP_modules" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.actions.PtActions.infer">
<code class="sig-name descname">infer</code><span class="sig-paren">(</span><em class="sig-param">tensors</em>, <em class="sig-param">checkpoint_dir=None</em>, <em class="sig-param">ckpt_pattern=''</em>, <em class="sig-param">verbose=True</em>, <em class="sig-param">cache=False</em>, <em class="sig-param">use_cache=False</em>, <em class="sig-param">offload_to_cpu=True</em>, <em class="sig-param">modules_to_restore=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/actions.html#PtActions.infer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.actions.PtActions.infer" title="Permalink to this definition">¶</a></dt>
<dd><p>See NeuralModuleFactory.infer()</p>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.actions.PtActions.nm_graph_forward_pass">
<code class="sig-name descname">nm_graph_forward_pass</code><span class="sig-paren">(</span><em class="sig-param">callchain</em>, <em class="sig-param">registered_tensors</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/actions.html#PtActions.nm_graph_forward_pass"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.actions.PtActions.nm_graph_forward_pass" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.actions.PtActions.optimizers">
<em class="property">property </em><code class="sig-name descname">optimizers</code><a class="headerlink" href="#nemo.backends.pytorch.actions.PtActions.optimizers" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.actions.PtActions.pad_tensor">
<em class="property">static </em><code class="sig-name descname">pad_tensor</code><span class="sig-paren">(</span><em class="sig-param">t: torch.Tensor</em>, <em class="sig-param">target_size: torch.Size</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/actions.html#PtActions.pad_tensor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.actions.PtActions.pad_tensor" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.actions.PtActions.restore_state_from">
<code class="sig-name descname">restore_state_from</code><span class="sig-paren">(</span><em class="sig-param">path: str</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/actions.html#PtActions.restore_state_from"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.actions.PtActions.restore_state_from" title="Permalink to this definition">¶</a></dt>
<dd><p>Restores state such as step, epoch and optimizer parameters
:param path:</p>
<p>Returns:</p>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.actions.PtActions.save_state_to">
<code class="sig-name descname">save_state_to</code><span class="sig-paren">(</span><em class="sig-param">path: str</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/actions.html#PtActions.save_state_to"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.actions.PtActions.save_state_to" title="Permalink to this definition">¶</a></dt>
<dd><p>Saves current state such as step, epoch and optimizer parameters
:param path:</p>
<p>Returns:</p>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.actions.PtActions.step">
<em class="property">property </em><code class="sig-name descname">step</code><a class="headerlink" href="#nemo.backends.pytorch.actions.PtActions.step" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.actions.PtActions.train">
<code class="sig-name descname">train</code><span class="sig-paren">(</span><em class="sig-param">tensors_to_optimize=None</em>, <em class="sig-param">training_graph=None</em>, <em class="sig-param">optimizer=None</em>, <em class="sig-param">optimization_params=None</em>, <em class="sig-param">callbacks: Optional[List[nemo.core.deprecated_callbacks.ActionCallback]] = None</em>, <em class="sig-param">lr_policy=None</em>, <em class="sig-param">batches_per_step=None</em>, <em class="sig-param">stop_on_nan_loss=False</em>, <em class="sig-param">synced_batchnorm=False</em>, <em class="sig-param">synced_batchnorm_groupsize=0</em>, <em class="sig-param">gradient_predivide=False</em>, <em class="sig-param">amp_max_loss_scale=16777216.0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/actions.html#PtActions.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.actions.PtActions.train" title="Permalink to this definition">¶</a></dt>
<dd><p>This action executes training and (optionally) evaluation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensors_to_optimize</strong> – which tensors to optimize. Typically this is
single loss tesnor.</p></li>
<li><p><strong>callbacks</strong> – list of callback objects</p></li>
<li><p><strong>lr_policy</strong> – function which should take (initial_lr, step, epoch) and
return learning rate</p></li>
<li><p><strong>batches_per_step</strong> – number of mini-batches to process before one
optimizer step. (default: None, same as 1). Use this
to simulate larger batch sizes on hardware which could not fit
larger batch in memory otherwise. Effectively, this will make
“algorithmic” batch size per GPU/worker = batches_per_step*
batch_size</p></li>
<li><p><strong>stop_on_nan_loss</strong> – (default: False) If set to True, the training
will stop if loss=nan or inf. If set to False, the training
will continue.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nemo.backends.pytorch.nm">
<span id="classes-for-writing-your-own-nms"></span><h2>Classes for writing your own NMs<a class="headerlink" href="#module-nemo.backends.pytorch.nm" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="nemo.backends.pytorch.nm.DataLayerNM">
<em class="property">class </em><code class="sig-prename descclassname">nemo.backends.pytorch.nm.</code><code class="sig-name descname">DataLayerNM</code><span class="sig-paren">(</span><em class="sig-param">name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#DataLayerNM"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.DataLayerNM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nemo.core.neural_modules.NeuralModule" title="nemo.core.neural_modules.NeuralModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.core.neural_modules.NeuralModule</span></code></a></p>
<p>A helper Base class for creating Pytorch-based data layers.
You must implement __len__ method to return dataset size and
data_iterator property to return iterator over the dataset.</p>
<dl class="method">
<dt id="nemo.backends.pytorch.nm.DataLayerNM.batch_size">
<em class="property">property </em><code class="sig-name descname">batch_size</code><a class="headerlink" href="#nemo.backends.pytorch.nm.DataLayerNM.batch_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Property returning the batch size.</p>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.DataLayerNM.data_iterator">
<em class="property">property </em><code class="sig-name descname">data_iterator</code><a class="headerlink" href="#nemo.backends.pytorch.nm.DataLayerNM.data_iterator" title="Permalink to this definition">¶</a></dt>
<dd><p>“Iterator over the dataset. It is a good idea to return
torch.utils.data.DataLoader here. Should implement either this or
<cite>dataset</cite>.
If this is implemented, <cite>dataset</cite> property should return None.</p>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.DataLayerNM.dataset">
<em class="property">abstract property </em><code class="sig-name descname">dataset</code><a class="headerlink" href="#nemo.backends.pytorch.nm.DataLayerNM.dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Should return an instance of torch.utils.data.Dataset. Should
implement
either this or <cite>data_iterator</cite>. If this is implemented, <cite>data_iterator</cite>
should return None.</p>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.DataLayerNM.freeze">
<code class="sig-name descname">freeze</code><span class="sig-paren">(</span><em class="sig-param">weights: Set[str] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#DataLayerNM.freeze"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.DataLayerNM.freeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Freeze weights</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>weights</strong> (<em>set</em>) – set of weight names to freeze</p></li>
<li><p><strong>None</strong><strong>, </strong><strong>all weights are freezed.</strong> (<em>If</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.DataLayerNM.get_weights">
<code class="sig-name descname">get_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#DataLayerNM.get_weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.DataLayerNM.get_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns NeuralModule’s weights copy.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Dictionary of name -&gt; (weights, trainable)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.DataLayerNM.input_ports">
<em class="property">property </em><code class="sig-name descname">input_ports</code><a class="headerlink" href="#nemo.backends.pytorch.nm.DataLayerNM.input_ports" title="Permalink to this definition">¶</a></dt>
<dd><p>DataLayer by definition does not have any input ports.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>An empty dictionary.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.DataLayerNM.num_weights">
<em class="property">property </em><code class="sig-name descname">num_weights</code><a class="headerlink" href="#nemo.backends.pytorch.nm.DataLayerNM.num_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of module’s weights</p>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.DataLayerNM.num_workers">
<em class="property">property </em><code class="sig-name descname">num_workers</code><a class="headerlink" href="#nemo.backends.pytorch.nm.DataLayerNM.num_workers" title="Permalink to this definition">¶</a></dt>
<dd><p>Property returning the number of workers.</p>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.DataLayerNM.pin_memory">
<em class="property">property </em><code class="sig-name descname">pin_memory</code><a class="headerlink" href="#nemo.backends.pytorch.nm.DataLayerNM.pin_memory" title="Permalink to this definition">¶</a></dt>
<dd><p>Property returning the pin memory flag.</p>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.DataLayerNM.restore_from">
<code class="sig-name descname">restore_from</code><span class="sig-paren">(</span><em class="sig-param">path</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#DataLayerNM.restore_from"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.DataLayerNM.restore_from" title="Permalink to this definition">¶</a></dt>
<dd><p>Restore module’s state from file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>path</strong> (<em>string</em>) – path to where to restore from.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.DataLayerNM.save_to">
<code class="sig-name descname">save_to</code><span class="sig-paren">(</span><em class="sig-param">path</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#DataLayerNM.save_to"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.DataLayerNM.save_to" title="Permalink to this definition">¶</a></dt>
<dd><p>Save module state to file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>path</strong> (<em>string</em>) – path to while where to save.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.DataLayerNM.set_weights">
<code class="sig-name descname">set_weights</code><span class="sig-paren">(</span><em class="sig-param">name2weight: Dict[str, bool], name2name_and_transform</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#DataLayerNM.set_weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.DataLayerNM.set_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets weight from given values. For every named weight in
name2weight,
if weight with the same name is found in the model, it will be set to
found value.</p>
<p>WARNING: This will NOT tie weights. It will copy values.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">name2name_and_transform</span></code> is provided then if will set weights
using
name mapping and transform. For example, suppose <code class="docutils literal notranslate"><span class="pre">objec1.X</span> <span class="pre">=</span> <span class="pre">3x5</span>
<span class="pre">weight</span></code>.
Then, if <code class="docutils literal notranslate"><span class="pre">name2name_and_transform['X']=('Y',</span>
<span class="pre">WeightShareTransform.TRANSPOSE)</span></code>
and <code class="docutils literal notranslate"><span class="pre">Y</span></code> is 5x3 weight and <code class="docutils literal notranslate"><span class="pre">name2weight['Y']=Y.</span> <span class="pre">Then:</span>
<span class="pre">``object1.set_weights(name2weight,</span> <span class="pre">name2name_and_transform)</span></code> will
set object1.X=transpose(Y).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name2weight</strong> (<em>dict</em>) – dictionary of name to (weight, trainable).</p></li>
<li><p><strong>this is output of get_weights method.</strong> (<em>Typically</em>) – </p></li>
<li><p><strong>name2name_and_transform</strong> – mapping from name -&gt; (name, transform)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.DataLayerNM.shuffle">
<em class="property">property </em><code class="sig-name descname">shuffle</code><a class="headerlink" href="#nemo.backends.pytorch.nm.DataLayerNM.shuffle" title="Permalink to this definition">¶</a></dt>
<dd><p>Property returning the shuffle flag.</p>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.DataLayerNM.tie_weights_with">
<code class="sig-name descname">tie_weights_with</code><span class="sig-paren">(</span><em class="sig-param">module</em>, <em class="sig-param">weight_names</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#DataLayerNM.tie_weights_with"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.DataLayerNM.tie_weights_with" title="Permalink to this definition">¶</a></dt>
<dd><p>Ties weights between self and module. For every weight name in
weight_names, if weight with the same name is found in self, it will
be tied
with a same weight from <code class="docutils literal notranslate"><span class="pre">module</span></code>.</p>
<p>WARNING: Once weights are tied, updates to one weights’s weights
will affect
other module’s weights.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">name2name_and_transform</span></code> is provided then if will set weights
using
name mapping and transform. For example, suppose <code class="docutils literal notranslate"><span class="pre">objec1.X</span> <span class="pre">=</span> <span class="pre">3x5</span>
<span class="pre">weights</span></code>
and <code class="docutils literal notranslate"><span class="pre">object2.Y</span> <span class="pre">=</span> <span class="pre">5x3</span> <span class="pre">weights</span></code>. Then these weights can be tied like
this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">object1</span><span class="o">.</span><span class="n">tie_weights_with</span><span class="p">(</span><span class="n">object2</span><span class="p">,</span> <span class="n">weight_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">],</span>
<span class="n">name2name_and_transform</span> <span class="o">=</span>
<span class="p">{</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">WeightShareTransform</span><span class="o">.</span><span class="n">TRANSPOSE</span><span class="p">)})</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> – with which module to tie weights</p></li>
<li><p><strong>weight_names</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – list of self weights’ names</p></li>
<li><p><strong>name2name_and_transform</strong> – mapping from name -&gt; (name, transform)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.DataLayerNM.unfreeze">
<code class="sig-name descname">unfreeze</code><span class="sig-paren">(</span><em class="sig-param">weights: Set[str] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#DataLayerNM.unfreeze"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.DataLayerNM.unfreeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Unfreeze weights</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>weights</strong> (<em>set</em>) – set of weight names to unfreeze</p></li>
<li><p><strong>None</strong><strong>, </strong><strong>all weights are unfreezed.</strong> (<em>If</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nemo.backends.pytorch.nm.LossNM">
<em class="property">class </em><code class="sig-prename descclassname">nemo.backends.pytorch.nm.</code><code class="sig-name descname">LossNM</code><span class="sig-paren">(</span><em class="sig-param">name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#LossNM"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.LossNM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nemo.core.neural_modules.NeuralModule" title="nemo.core.neural_modules.NeuralModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.core.neural_modules.NeuralModule</span></code></a></p>
<p>A helper Base class for creating Pytorch-based loss function modules.
You must implement _loss_function method.</p>
<dl class="method">
<dt id="nemo.backends.pytorch.nm.LossNM.freeze">
<code class="sig-name descname">freeze</code><span class="sig-paren">(</span><em class="sig-param">weights: Set[str] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#LossNM.freeze"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.LossNM.freeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Freeze weights</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>weights</strong> (<em>set</em>) – set of weight names to freeze</p></li>
<li><p><strong>None</strong><strong>, </strong><strong>all weights are freezed.</strong> (<em>If</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.LossNM.get_weights">
<code class="sig-name descname">get_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#LossNM.get_weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.LossNM.get_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns NeuralModule’s weights copy.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Dictionary of name -&gt; (weights, trainable)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.LossNM.num_weights">
<em class="property">property </em><code class="sig-name descname">num_weights</code><a class="headerlink" href="#nemo.backends.pytorch.nm.LossNM.num_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of module’s weights</p>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.LossNM.restore_from">
<code class="sig-name descname">restore_from</code><span class="sig-paren">(</span><em class="sig-param">path</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#LossNM.restore_from"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.LossNM.restore_from" title="Permalink to this definition">¶</a></dt>
<dd><p>Restore module’s state from file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>path</strong> (<em>string</em>) – path to where to restore from.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.LossNM.save_to">
<code class="sig-name descname">save_to</code><span class="sig-paren">(</span><em class="sig-param">path</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#LossNM.save_to"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.LossNM.save_to" title="Permalink to this definition">¶</a></dt>
<dd><p>Save module state to file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>path</strong> (<em>string</em>) – path to while where to save.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.LossNM.set_weights">
<code class="sig-name descname">set_weights</code><span class="sig-paren">(</span><em class="sig-param">name2weight: Dict[str, bool], name2name_and_transform</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#LossNM.set_weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.LossNM.set_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets weight from given values. For every named weight in
name2weight,
if weight with the same name is found in the model, it will be set to
found value.</p>
<p>WARNING: This will NOT tie weights. It will copy values.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">name2name_and_transform</span></code> is provided then if will set weights
using
name mapping and transform. For example, suppose <code class="docutils literal notranslate"><span class="pre">objec1.X</span> <span class="pre">=</span> <span class="pre">3x5</span>
<span class="pre">weight</span></code>.
Then, if <code class="docutils literal notranslate"><span class="pre">name2name_and_transform['X']=('Y',</span>
<span class="pre">WeightShareTransform.TRANSPOSE)</span></code>
and <code class="docutils literal notranslate"><span class="pre">Y</span></code> is 5x3 weight and <code class="docutils literal notranslate"><span class="pre">name2weight['Y']=Y.</span> <span class="pre">Then:</span>
<span class="pre">``object1.set_weights(name2weight,</span> <span class="pre">name2name_and_transform)</span></code> will
set object1.X=transpose(Y).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name2weight</strong> (<em>dict</em>) – dictionary of name to (weight, trainable).</p></li>
<li><p><strong>this is output of get_weights method.</strong> (<em>Typically</em>) – </p></li>
<li><p><strong>name2name_and_transform</strong> – mapping from name -&gt; (name, transform)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.LossNM.tie_weights_with">
<code class="sig-name descname">tie_weights_with</code><span class="sig-paren">(</span><em class="sig-param">module</em>, <em class="sig-param">weight_names</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#LossNM.tie_weights_with"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.LossNM.tie_weights_with" title="Permalink to this definition">¶</a></dt>
<dd><p>Ties weights between self and module. For every weight name in
weight_names, if weight with the same name is found in self, it will
be tied
with a same weight from <code class="docutils literal notranslate"><span class="pre">module</span></code>.</p>
<p>WARNING: Once weights are tied, updates to one weights’s weights
will affect
other module’s weights.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">name2name_and_transform</span></code> is provided then if will set weights
using
name mapping and transform. For example, suppose <code class="docutils literal notranslate"><span class="pre">objec1.X</span> <span class="pre">=</span> <span class="pre">3x5</span>
<span class="pre">weights</span></code>
and <code class="docutils literal notranslate"><span class="pre">object2.Y</span> <span class="pre">=</span> <span class="pre">5x3</span> <span class="pre">weights</span></code>. Then these weights can be tied like
this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">object1</span><span class="o">.</span><span class="n">tie_weights_with</span><span class="p">(</span><span class="n">object2</span><span class="p">,</span> <span class="n">weight_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">],</span>
<span class="n">name2name_and_transform</span> <span class="o">=</span>
<span class="p">{</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">WeightShareTransform</span><span class="o">.</span><span class="n">TRANSPOSE</span><span class="p">)})</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> – with which module to tie weights</p></li>
<li><p><strong>weight_names</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – list of self weights’ names</p></li>
<li><p><strong>name2name_and_transform</strong> – mapping from name -&gt; (name, transform)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.LossNM.unfreeze">
<code class="sig-name descname">unfreeze</code><span class="sig-paren">(</span><em class="sig-param">weights: Set[str] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#LossNM.unfreeze"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.LossNM.unfreeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Unfreeze weights</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>weights</strong> (<em>set</em>) – set of weight names to unfreeze</p></li>
<li><p><strong>None</strong><strong>, </strong><strong>all weights are unfreezed.</strong> (<em>If</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nemo.backends.pytorch.nm.NonTrainableNM">
<em class="property">class </em><code class="sig-prename descclassname">nemo.backends.pytorch.nm.</code><code class="sig-name descname">NonTrainableNM</code><span class="sig-paren">(</span><em class="sig-param">name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#NonTrainableNM"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.NonTrainableNM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nemo.core.neural_modules.NeuralModule" title="nemo.core.neural_modules.NeuralModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.core.neural_modules.NeuralModule</span></code></a></p>
<dl class="method">
<dt id="nemo.backends.pytorch.nm.NonTrainableNM.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">*input</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#NonTrainableNM.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.NonTrainableNM.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.NonTrainableNM.freeze">
<code class="sig-name descname">freeze</code><span class="sig-paren">(</span><em class="sig-param">weights: Set[str] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#NonTrainableNM.freeze"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.NonTrainableNM.freeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Freeze weights</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>weights</strong> (<em>set</em>) – set of weight names to freeze</p></li>
<li><p><strong>None</strong><strong>, </strong><strong>all weights are freezed.</strong> (<em>If</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.NonTrainableNM.get_weights">
<code class="sig-name descname">get_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Optional[Dict[str, bool]]<a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#NonTrainableNM.get_weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.NonTrainableNM.get_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns NeuralModule’s weights copy.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Dictionary of name -&gt; (weights, trainable)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.NonTrainableNM.num_weights">
<em class="property">property </em><code class="sig-name descname">num_weights</code><a class="headerlink" href="#nemo.backends.pytorch.nm.NonTrainableNM.num_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of module’s weights</p>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.NonTrainableNM.restore_from">
<code class="sig-name descname">restore_from</code><span class="sig-paren">(</span><em class="sig-param">path: str</em>, <em class="sig-param">local_rank: int = 0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#NonTrainableNM.restore_from"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.NonTrainableNM.restore_from" title="Permalink to this definition">¶</a></dt>
<dd><p>Restore module’s state from file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>path</strong> (<em>string</em>) – path to where to restore from.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.NonTrainableNM.save_to">
<code class="sig-name descname">save_to</code><span class="sig-paren">(</span><em class="sig-param">path: str</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#NonTrainableNM.save_to"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.NonTrainableNM.save_to" title="Permalink to this definition">¶</a></dt>
<dd><p>Save module state to file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>path</strong> (<em>string</em>) – path to while where to save.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.NonTrainableNM.set_weights">
<code class="sig-name descname">set_weights</code><span class="sig-paren">(</span><em class="sig-param">name2weight: Dict[str, Tuple[str, bool]], name2name_and_transform: Dict[str, Tuple[str, nemo.core.neural_modules.WeightShareTransform]] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#NonTrainableNM.set_weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.NonTrainableNM.set_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets weight from given values. For every named weight in
name2weight,
if weight with the same name is found in the model, it will be set to
found value.</p>
<p>WARNING: This will NOT tie weights. It will copy values.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">name2name_and_transform</span></code> is provided then if will set weights
using
name mapping and transform. For example, suppose <code class="docutils literal notranslate"><span class="pre">objec1.X</span> <span class="pre">=</span> <span class="pre">3x5</span>
<span class="pre">weight</span></code>.
Then, if <code class="docutils literal notranslate"><span class="pre">name2name_and_transform['X']=('Y',</span>
<span class="pre">WeightShareTransform.TRANSPOSE)</span></code>
and <code class="docutils literal notranslate"><span class="pre">Y</span></code> is 5x3 weight and <code class="docutils literal notranslate"><span class="pre">name2weight['Y']=Y.</span> <span class="pre">Then:</span>
<span class="pre">``object1.set_weights(name2weight,</span> <span class="pre">name2name_and_transform)</span></code> will
set object1.X=transpose(Y).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name2weight</strong> (<em>dict</em>) – dictionary of name to (weight, trainable).</p></li>
<li><p><strong>this is output of get_weights method.</strong> (<em>Typically</em>) – </p></li>
<li><p><strong>name2name_and_transform</strong> – mapping from name -&gt; (name, transform)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.NonTrainableNM.tie_weights_with">
<code class="sig-name descname">tie_weights_with</code><span class="sig-paren">(</span><em class="sig-param">module, weight_names=typing.List[str], name2name_and_transform: Dict[str, Tuple[str, nemo.core.neural_modules.WeightShareTransform]] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#NonTrainableNM.tie_weights_with"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.NonTrainableNM.tie_weights_with" title="Permalink to this definition">¶</a></dt>
<dd><p>Ties weights between self and module. For every weight name in
weight_names, if weight with the same name is found in self, it will
be tied
with a same weight from <code class="docutils literal notranslate"><span class="pre">module</span></code>.</p>
<p>WARNING: Once weights are tied, updates to one weights’s weights
will affect
other module’s weights.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">name2name_and_transform</span></code> is provided then if will set weights
using
name mapping and transform. For example, suppose <code class="docutils literal notranslate"><span class="pre">objec1.X</span> <span class="pre">=</span> <span class="pre">3x5</span>
<span class="pre">weights</span></code>
and <code class="docutils literal notranslate"><span class="pre">object2.Y</span> <span class="pre">=</span> <span class="pre">5x3</span> <span class="pre">weights</span></code>. Then these weights can be tied like
this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">object1</span><span class="o">.</span><span class="n">tie_weights_with</span><span class="p">(</span><span class="n">object2</span><span class="p">,</span> <span class="n">weight_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">],</span>
<span class="n">name2name_and_transform</span> <span class="o">=</span>
<span class="p">{</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">WeightShareTransform</span><span class="o">.</span><span class="n">TRANSPOSE</span><span class="p">)})</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> – with which module to tie weights</p></li>
<li><p><strong>weight_names</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – list of self weights’ names</p></li>
<li><p><strong>name2name_and_transform</strong> – mapping from name -&gt; (name, transform)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.NonTrainableNM.unfreeze">
<code class="sig-name descname">unfreeze</code><span class="sig-paren">(</span><em class="sig-param">weights: Set[str] = None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#NonTrainableNM.unfreeze"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.NonTrainableNM.unfreeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Unfreeze weights</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>weights</strong> (<em>set</em>) – set of weight names to unfreeze</p></li>
<li><p><strong>None</strong><strong>, </strong><strong>all weights are unfreezed.</strong> (<em>If</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nemo.backends.pytorch.nm.TrainableNM">
<em class="property">class </em><code class="sig-prename descclassname">nemo.backends.pytorch.nm.</code><code class="sig-name descname">TrainableNM</code><span class="sig-paren">(</span><em class="sig-param">pretrained_model_name=None</em>, <em class="sig-param">name=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#TrainableNM"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.TrainableNM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nemo.core.neural_modules.NeuralModule" title="nemo.core.neural_modules.NeuralModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.core.neural_modules.NeuralModule</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>A helper Base class for NeuralModule’s based on Pytorch’s nn.Module.</p>
<p>If you have a Pytorch class which derives from nn.Module you can
covert it into a NeuralModule, by replacing inheriting from this class
instead</p>
<p>Your constructor then should look like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
  <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
  <span class="o">....</span> <span class="c1"># your code</span>
</pre></div>
</div>
<p>Then make sure that your forward(..) method accepts arguments named like
input ports.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>pretrained_model_name</strong> (<em>str</em>) – name of pretrained model to use in order
to initialize this neural module</p>
</dd>
</dl>
<dl class="method">
<dt id="nemo.backends.pytorch.nm.TrainableNM.freeze">
<code class="sig-name descname">freeze</code><span class="sig-paren">(</span><em class="sig-param">weights=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#TrainableNM.freeze"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.TrainableNM.freeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Freeze weights</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>weights</strong> (<em>set</em>) – set of weight names to freeze</p></li>
<li><p><strong>None</strong><strong>, </strong><strong>all weights are freezed.</strong> (<em>If</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.TrainableNM.get_weights">
<code class="sig-name descname">get_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#TrainableNM.get_weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.TrainableNM.get_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns NeuralModule’s weights copy.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Dictionary of name -&gt; (weights, trainable)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.TrainableNM.is_frozen">
<code class="sig-name descname">is_frozen</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; bool<a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#TrainableNM.is_frozen"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.TrainableNM.is_frozen" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns:
True/False depending whether there are any frozen weights or not.</p>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.TrainableNM.num_weights">
<em class="property">property </em><code class="sig-name descname">num_weights</code><a class="headerlink" href="#nemo.backends.pytorch.nm.TrainableNM.num_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of module’s weights</p>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.TrainableNM.operation_mode">
<em class="property">property </em><code class="sig-name descname">operation_mode</code><a class="headerlink" href="#nemo.backends.pytorch.nm.TrainableNM.operation_mode" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the operation mode.</p>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.TrainableNM.restore_from">
<code class="sig-name descname">restore_from</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">local_rank=0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#TrainableNM.restore_from"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.TrainableNM.restore_from" title="Permalink to this definition">¶</a></dt>
<dd><p>Restore module’s state from file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>path</strong> (<em>string</em>) – path to where to restore from.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.TrainableNM.save_to">
<code class="sig-name descname">save_to</code><span class="sig-paren">(</span><em class="sig-param">path</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#TrainableNM.save_to"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.TrainableNM.save_to" title="Permalink to this definition">¶</a></dt>
<dd><p>Save module state to file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>path</strong> (<em>string</em>) – path to while where to save.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.TrainableNM.set_weights">
<code class="sig-name descname">set_weights</code><span class="sig-paren">(</span><em class="sig-param">name2weight</em>, <em class="sig-param">name2name_and_transform=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#TrainableNM.set_weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.TrainableNM.set_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets weight from given values. For every named weight in
name2weight,
if weight with the same name is found in the model, it will be set to
found value.</p>
<p>WARNING: This will NOT tie weights. It will copy values.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">name2name_and_transform</span></code> is provided then if will set weights
using
name mapping and transform. For example, suppose <code class="docutils literal notranslate"><span class="pre">objec1.X</span> <span class="pre">=</span> <span class="pre">3x5</span>
<span class="pre">weight</span></code>.
Then, if <code class="docutils literal notranslate"><span class="pre">name2name_and_transform['X']=('Y',</span>
<span class="pre">WeightShareTransform.TRANSPOSE)</span></code>
and <code class="docutils literal notranslate"><span class="pre">Y</span></code> is 5x3 weight and <code class="docutils literal notranslate"><span class="pre">name2weight['Y']=Y.</span> <span class="pre">Then:</span>
<span class="pre">``object1.set_weights(name2weight,</span> <span class="pre">name2name_and_transform)</span></code> will
set object1.X=transpose(Y).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name2weight</strong> (<em>dict</em>) – dictionary of name to (weight, trainable).</p></li>
<li><p><strong>this is output of get_weights method.</strong> (<em>Typically</em>) – </p></li>
<li><p><strong>name2name_and_transform</strong> – mapping from name -&gt; (name, transform)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.TrainableNM.tie_weights_with">
<code class="sig-name descname">tie_weights_with</code><span class="sig-paren">(</span><em class="sig-param">module</em>, <em class="sig-param">weight_names</em>, <em class="sig-param">name2name_and_transform=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#TrainableNM.tie_weights_with"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.TrainableNM.tie_weights_with" title="Permalink to this definition">¶</a></dt>
<dd><p>Ties weights between self and module. For every weight name in
weight_names, if weight with the same name is found in self, it will
be tied
with a same weight from <code class="docutils literal notranslate"><span class="pre">module</span></code>.</p>
<p>WARNING: Once weights are tied, updates to one weights’s weights
will affect
other module’s weights.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">name2name_and_transform</span></code> is provided then if will set weights
using
name mapping and transform. For example, suppose <code class="docutils literal notranslate"><span class="pre">objec1.X</span> <span class="pre">=</span> <span class="pre">3x5</span>
<span class="pre">weights</span></code>
and <code class="docutils literal notranslate"><span class="pre">object2.Y</span> <span class="pre">=</span> <span class="pre">5x3</span> <span class="pre">weights</span></code>. Then these weights can be tied like
this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">object1</span><span class="o">.</span><span class="n">tie_weights_with</span><span class="p">(</span><span class="n">object2</span><span class="p">,</span> <span class="n">weight_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">],</span>
<span class="n">name2name_and_transform</span> <span class="o">=</span>
<span class="p">{</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">WeightShareTransform</span><span class="o">.</span><span class="n">TRANSPOSE</span><span class="p">)})</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> – with which module to tie weights</p></li>
<li><p><strong>weight_names</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – list of self weights’ names</p></li>
<li><p><strong>name2name_and_transform</strong> – mapping from name -&gt; (name, transform)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.nm.TrainableNM.unfreeze">
<code class="sig-name descname">unfreeze</code><span class="sig-paren">(</span><em class="sig-param">weights=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/nm.html#TrainableNM.unfreeze"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.nm.TrainableNM.unfreeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Unfreeze weights</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>weights</strong> (<em>set</em>) – set of weight names to unfreeze</p></li>
<li><p><strong>None</strong><strong>, </strong><strong>all weights are unfreezed.</strong> (<em>If</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nemo.backends.pytorch.module_wrapper">
<span id="trainable-module-wrapper"></span><h2>Trainable Module Wrapper<a class="headerlink" href="#module-nemo.backends.pytorch.module_wrapper" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper">
<em class="property">class </em><code class="sig-prename descclassname">nemo.backends.pytorch.module_wrapper.</code><code class="sig-name descname">TrainableNeuralModuleWrapper</code><span class="sig-paren">(</span><em class="sig-param">pt_nn_module</em>, <em class="sig-param">input_ports_dict</em>, <em class="sig-param">output_ports_dict</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/module_wrapper.html#TrainableNeuralModuleWrapper"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nemo.core.neural_modules.NeuralModule" title="nemo.core.neural_modules.NeuralModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.core.neural_modules.NeuralModule</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>This class wraps an instance of Pytorch’s nn.Module and
returns NeuralModule’s instance.</p>
<dl class="method">
<dt id="nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper.eval">
<code class="sig-name descname">eval</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/module_wrapper.html#TrainableNeuralModuleWrapper.eval"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper.eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the module in evaluation mode.</p>
<p>This has any effect only on certain modules. See documentations of
particular modules for details of their behaviors in training/evaluation
mode, if they are affected, e.g. <code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm</span></code>,
etc.</p>
<p>This is equivalent with <code class="xref py py-meth docutils literal notranslate"><span class="pre">self.train(False)</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper.freeze">
<code class="sig-name descname">freeze</code><span class="sig-paren">(</span><em class="sig-param">weights=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/module_wrapper.html#TrainableNeuralModuleWrapper.freeze"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper.freeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Freeze weights</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>weights</strong> (<em>set</em>) – set of weight names to freeze</p></li>
<li><p><strong>None</strong><strong>, </strong><strong>all weights are freezed.</strong> (<em>If</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper.get_weights">
<code class="sig-name descname">get_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/module_wrapper.html#TrainableNeuralModuleWrapper.get_weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper.get_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns NeuralModule’s weights copy.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Dictionary of name -&gt; (weights, trainable)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper.input_ports">
<em class="property">property </em><code class="sig-name descname">input_ports</code><a class="headerlink" href="#nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper.input_ports" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns definitions of module input ports.</p>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper.named_parameters">
<code class="sig-name descname">named_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/module_wrapper.html#TrainableNeuralModuleWrapper.named_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper.named_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module parameters, yielding both the
name of the parameter as well as the parameter itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prefix</strong> (<em>str</em>) – prefix to prepend to all parameter names.</p></li>
<li><p><strong>recurse</strong> (<em>bool</em>) – if True, then yields parameters of this module
and all submodules. Otherwise, yields only parameters that
are direct members of this module.</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>(string, Parameter)</em> – Tuple containing the name and parameter</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;bias&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>       <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper.num_weights">
<em class="property">property </em><code class="sig-name descname">num_weights</code><a class="headerlink" href="#nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper.num_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Number of module’s weights</p>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper.output_ports">
<em class="property">property </em><code class="sig-name descname">output_ports</code><a class="headerlink" href="#nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper.output_ports" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns definitions of module output ports.</p>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper.parameters">
<code class="sig-name descname">parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/module_wrapper.html#TrainableNeuralModuleWrapper.parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper.parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module parameters.</p>
<p>This is typically passed to an optimizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>recurse</strong> (<em>bool</em>) – if True, then yields parameters of this module
and all submodules. Otherwise, yields only parameters that
are direct members of this module.</p>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>Parameter</em> – module parameter</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="p">),</span> <span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">&lt;class &#39;torch.FloatTensor&#39;&gt; (20L,)</span>
<span class="go">&lt;class &#39;torch.FloatTensor&#39;&gt; (20L, 1L, 5L, 5L)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper.restore_from">
<code class="sig-name descname">restore_from</code><span class="sig-paren">(</span><em class="sig-param">path</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/module_wrapper.html#TrainableNeuralModuleWrapper.restore_from"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper.restore_from" title="Permalink to this definition">¶</a></dt>
<dd><p>Restore module’s state from file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>path</strong> (<em>string</em>) – path to where to restore from.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper.save_to">
<code class="sig-name descname">save_to</code><span class="sig-paren">(</span><em class="sig-param">path</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/module_wrapper.html#TrainableNeuralModuleWrapper.save_to"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper.save_to" title="Permalink to this definition">¶</a></dt>
<dd><p>Save module state to file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>path</strong> (<em>string</em>) – path to while where to save.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper.set_weights">
<code class="sig-name descname">set_weights</code><span class="sig-paren">(</span><em class="sig-param">name2weight</em>, <em class="sig-param">name2name_and_transform=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/module_wrapper.html#TrainableNeuralModuleWrapper.set_weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper.set_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets weight from given values. For every named weight in
name2weight,
if weight with the same name is found in the model, it will be set to
found value.</p>
<p>WARNING: This will NOT tie weights. It will copy values.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">name2name_and_transform</span></code> is provided then if will set weights
using
name mapping and transform. For example, suppose <code class="docutils literal notranslate"><span class="pre">objec1.X</span> <span class="pre">=</span> <span class="pre">3x5</span>
<span class="pre">weight</span></code>.
Then, if <code class="docutils literal notranslate"><span class="pre">name2name_and_transform['X']=('Y',</span>
<span class="pre">WeightShareTransform.TRANSPOSE)</span></code>
and <code class="docutils literal notranslate"><span class="pre">Y</span></code> is 5x3 weight and <code class="docutils literal notranslate"><span class="pre">name2weight['Y']=Y.</span> <span class="pre">Then:</span>
<span class="pre">``object1.set_weights(name2weight,</span> <span class="pre">name2name_and_transform)</span></code> will
set object1.X=transpose(Y).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name2weight</strong> (<em>dict</em>) – dictionary of name to (weight, trainable).</p></li>
<li><p><strong>this is output of get_weights method.</strong> (<em>Typically</em>) – </p></li>
<li><p><strong>name2name_and_transform</strong> – mapping from name -&gt; (name, transform)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper.tie_weights_with">
<code class="sig-name descname">tie_weights_with</code><span class="sig-paren">(</span><em class="sig-param">module</em>, <em class="sig-param">weight_names</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/module_wrapper.html#TrainableNeuralModuleWrapper.tie_weights_with"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper.tie_weights_with" title="Permalink to this definition">¶</a></dt>
<dd><p>Ties weights between self and module. For every weight name in
weight_names, if weight with the same name is found in self, it will
be tied
with a same weight from <code class="docutils literal notranslate"><span class="pre">module</span></code>.</p>
<p>WARNING: Once weights are tied, updates to one weights’s weights
will affect
other module’s weights.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">name2name_and_transform</span></code> is provided then if will set weights
using
name mapping and transform. For example, suppose <code class="docutils literal notranslate"><span class="pre">objec1.X</span> <span class="pre">=</span> <span class="pre">3x5</span>
<span class="pre">weights</span></code>
and <code class="docutils literal notranslate"><span class="pre">object2.Y</span> <span class="pre">=</span> <span class="pre">5x3</span> <span class="pre">weights</span></code>. Then these weights can be tied like
this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">object1</span><span class="o">.</span><span class="n">tie_weights_with</span><span class="p">(</span><span class="n">object2</span><span class="p">,</span> <span class="n">weight_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">],</span>
<span class="n">name2name_and_transform</span> <span class="o">=</span>
<span class="p">{</span> <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">WeightShareTransform</span><span class="o">.</span><span class="n">TRANSPOSE</span><span class="p">)})</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> – with which module to tie weights</p></li>
<li><p><strong>weight_names</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – list of self weights’ names</p></li>
<li><p><strong>name2name_and_transform</strong> – mapping from name -&gt; (name, transform)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper.train">
<code class="sig-name descname">train</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/module_wrapper.html#TrainableNeuralModuleWrapper.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the module in training mode.</p>
<p>This has any effect only on certain modules. See documentations of
particular modules for details of their behaviors in training/evaluation
mode, if they are affected, e.g. <code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm</span></code>,
etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mode</strong> (<em>bool</em>) – whether to set training mode (<code class="docutils literal notranslate"><span class="pre">True</span></code>) or evaluation
mode (<code class="docutils literal notranslate"><span class="pre">False</span></code>). Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper.unfreeze">
<code class="sig-name descname">unfreeze</code><span class="sig-paren">(</span><em class="sig-param">weights=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nemo/backends/pytorch/module_wrapper.html#TrainableNeuralModuleWrapper.unfreeze"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nemo.backends.pytorch.module_wrapper.TrainableNeuralModuleWrapper.unfreeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Unfreeze weights</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>weights</strong> (<em>set</em>) – set of weight names to unfreeze</p></li>
<li><p><strong>None</strong><strong>, </strong><strong>all weights are unfreezed.</strong> (<em>If</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../chinese/intro.html" class="btn btn-neutral float-right" title="中文支持" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="modules.html" class="btn btn-neutral float-left" title="NeMo API" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018-2020, NVIDIA

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>